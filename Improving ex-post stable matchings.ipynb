{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6c60445-8209-43a0-98ad-41b236ec1a61",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1791793-5d3a-42a3-b836-f6d123a7ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Classes import Data, Assignment\n",
    "    # Later, we can move the Class definitions into a separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64e396b6-002b-40bf-bec9-222cf5e75f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pulp in c:\\users\\tdemeule\\appdata\\local\\anaconda3\\lib\\site-packages (2.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: gurobipy in c:\\users\\tdemeule\\appdata\\local\\anaconda3\\lib\\site-packages (12.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyscipopt in c:\\users\\tdemeule\\appdata\\local\\anaconda3\\lib\\site-packages (5.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pulp\n",
    "\n",
    "# Install Gurobi\n",
    "%pip install gurobipy \n",
    "    # Obtain academic license from: https://www.gurobi.com/downloads/end-user-license-agreement-academic/\n",
    "\n",
    "# Install SCIP\n",
    "%pip install pyscipopt\n",
    "\n",
    "# Other useful packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy # To make deep copies\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from numpy.random import default_rng\n",
    "from scipy.stats import norm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf67a65-30ee-4695-ac1f-31783c45f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GUROBI', 'GUROBI_CMD', 'PULP_CBC_CMD', 'SCIP_CMD', 'FSCIP_CMD', 'SCIP_PY']\n"
     ]
    }
   ],
   "source": [
    "# Check with solvers available on computer\n",
    "import pulp as pl\n",
    "from pulp import *\n",
    "solver_list = pl.listSolvers(onlyAvailable=True)\n",
    "print(solver_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5377d60-7775-4aab-bc4b-55f2abed7ffb",
   "metadata": {},
   "source": [
    "## Define classes\n",
    "Define the following classes:\n",
    "* 'Data': contains\n",
    "    * Number of students\n",
    "    * Number of schools\n",
    "    * Preferences students\n",
    "    * Preferences schools\n",
    "    * Capacities schools\n",
    "    * Names of students\n",
    "    * Names of schools\n",
    "    * File name\n",
    "* 'Assignment': the selection probabilities of the students to the schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2326dc72-5b8e-48fd-9b08-71591f6cf78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    # Define the initialization of an object from this class\n",
    "    def __init__(self, n_stud: int, n_schools: int, pref: list, prior: list, cap:list, ID_stud:list, ID_school:list, file_name:str):\n",
    "        self.n_stud = n_stud\n",
    "        self.n_schools = n_schools\n",
    "        self.pref = copy.deepcopy(pref)\n",
    "        self.prior = copy.deepcopy(prior)\n",
    "        self.cap = copy.deepcopy(cap)\n",
    "        self.ID_stud = copy.deepcopy(ID_stud)\n",
    "        self.ID_school = copy.deepcopy(ID_school)\n",
    "        self.file_name = file_name   \n",
    "\n",
    "        # Create alternative copies of pref and prior in which the elements are no longer strings, \n",
    "        # but the indices of the corresponding elements in the ID vectors\n",
    "        self.pref_index = [[self.ID_school.index(school) for school in student_pref] for student_pref in self.pref]\n",
    "\n",
    "        # Now create two matrices containing the position of the schools in the preferences, and of the students in the priorities\n",
    "        # Initialize the rank matrix with NaN\n",
    "        self.rank_pref = np.full((self.n_stud, self.n_schools), np.nan)\n",
    "\n",
    "        self.prior_index = []\n",
    "        for school_prior in self.prior:\n",
    "            transformed_school_prior = []\n",
    "            for student_group in school_prior:\n",
    "                if isinstance(student_group, tuple):\n",
    "                    transformed_school_prior.append(tuple(ID_stud.index(student) for student in student_group))\n",
    "                else:\n",
    "                    transformed_school_prior.append(ID_stud.index(student_group))\n",
    "            self.prior_index.append(transformed_school_prior)\n",
    "\n",
    "        \n",
    "        # Populate the rank matrix\n",
    "        for i, student_pref in enumerate(self.pref):\n",
    "            for rank_position, school_id in enumerate(student_pref):\n",
    "                if school_id in self.ID_school:\n",
    "                    school_index = self.ID_school.index(school_id)\n",
    "                    self.rank_pref[i][school_index] = rank_position\n",
    "\n",
    "        # Initialize the rank_prior matrix with NaN\n",
    "        self.rank_prior = np.full((self.n_schools, self.n_stud), np.nan)\n",
    "        \n",
    "        # Populate the rank_prior matrix\n",
    "        for j, school_prior in enumerate(self.prior):\n",
    "            for rank_position, student_id in enumerate(school_prior):\n",
    "                # Handle tuple (grouped students) by expanding\n",
    "                if isinstance(student_id, tuple):\n",
    "                    for grouped_student in student_id:\n",
    "                        if grouped_student in self.ID_stud:\n",
    "                            student_index = self.ID_stud.index(grouped_student)\n",
    "                            self.rank_prior[j][student_index] = rank_position + 1  # Positions are 1-based\n",
    "                elif student_id in self.ID_stud:\n",
    "                    student_index = self.ID_stud.index(student_id)\n",
    "                    self.rank_prior[j][student_index] = rank_position + 1  # Positions are 1-based\n",
    "    \n",
    "    # Choose what is being shown for the command 'print(MyData)', where 'MyData' is an instance of the class 'Data'\n",
    "    def __str__(self):\n",
    "        s =\"The data instance has the following properties: \\n\"\n",
    "        s += f\"\\n\\t{self.n_stud} students.\\n\\t{self.n_schools} schools. \\n\\n \\tPREFERENCES:\\n\"\n",
    "        for i in range(0,self.n_stud):\n",
    "            s+= f\"\\t{self.ID_stud[i]}\\t\"\n",
    "            for j in range(0, len(self.pref[i])):\n",
    "                s+=f\"{self.pref[i][j]} \"\n",
    "            s +=\"\\n\"\n",
    "\n",
    "        s += f\"\\n\\n \\tCAPACITIES & PRIORITIES:\\n\"\n",
    "        for i in range(0,self.n_schools):\n",
    "            s+= f\"\\t{self.ID_school[i]}\\t\"\n",
    "            s+= f\"{self.cap[i]}\\t\"\n",
    "            for j in range(0, len(self.prior[i])):\n",
    "                if len(self.prior[i][j]) >= 2:\n",
    "                    s+=f\"{{\"\n",
    "                    for k in range(0, len(self.prior[i][j])):\n",
    "                        s+=f\"{self.prior[i][j][k]}\"\n",
    "                        if k < len(self.prior[i][j]) - 1:\n",
    "                            s+= f\" \"\n",
    "                    s+=f\"}} \"\n",
    "                else:\n",
    "                    s+=f\"{self.prior[i][j]} \"\n",
    "            s +=\"\\n\"\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f9cd87d-cfc4-4f9e-ad89-eb06e68cc1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assignment:\n",
    "    # This class will contain an assignment\n",
    "    def __init__(self, MyData: Data, p: np.ndarray, label = None):\n",
    "        # self.file_name = MyData.file_name[:-4] \n",
    "            # Use this when importing .csv files, for example\n",
    "        self.file_name = MyData.file_name\n",
    "        self.MyData = copy.deepcopy(MyData)\n",
    "        self.assignment = copy.deepcopy(p)\n",
    "        self.label = label\n",
    "        if label == None:\n",
    "            self.label = \"\"\n",
    "        \n",
    "        names = []\n",
    "        for i in range(0,MyData.n_stud):\n",
    "            names.append(\"Choice {}\".format(i + 1))\n",
    "        \n",
    "        # Same as assignment, but ranked in decreasing order of preference\n",
    "        self.assignment_ranked = np.zeros(shape=(MyData.n_stud, MyData.n_schools), dtype = np.float64)\n",
    "        counter =  0\n",
    "        for i in range(0, MyData.n_stud):\n",
    "            for j in range(0, len(MyData.pref[i])):\n",
    "                \n",
    "                # Convert pref[i][k] (school ID as string) to column index\n",
    "                col_index = int(MyData.pref[i][j]) - 1\n",
    "                self.assignment_ranked[i][j] = self.assignment[i][col_index]\n",
    "                counter += 1\n",
    "        #self.assignment_ranked = pd.DataFrame(ranked, columns = names)\n",
    "\n",
    "    \n",
    "        # Export assignment\n",
    "        self.export_assignment()\n",
    "    \n",
    "    # Visualize the assignment in different ways\n",
    "    def visualize(self):\n",
    "        # To export the figures, check if the correct folder exists:\n",
    "        if os.path.exists(\"Results\") == False:\n",
    "            # If not, create folder\n",
    "            os.makedirs(\"Results\")\n",
    "        \n",
    "        s = os.path.join(\"Results\", \"Visualisations\")\n",
    "        if os.path.exists(s) == False:\n",
    "            # If not, create folder\n",
    "            os.makedirs(s)\n",
    "        \n",
    "        s = os.path.join(\"Results\", \"Visualisations\",self.file_name)\n",
    "        if os.path.exists(s) == False:\n",
    "            os.makedirs(s)\n",
    "            \n",
    "        \n",
    "        path = \"Results/Visualisations/\"\n",
    "        # The assignment itself\n",
    "        sns.set(rc = {'figure.figsize':(MyData.n_stud,MyData.n_schools/1.5)})\n",
    "        \n",
    "        # Create a custom colormap (to show negative values red)\n",
    "        colors = [\"red\", \"white\", \"blue\"]  # Red for negatives, white for 0, blue for positives\n",
    "        custom_cmap = LinearSegmentedColormap.from_list(\"CustomMap\", colors)\n",
    "        \n",
    "        # Create the heatmap\n",
    "        p = sns.heatmap(self.assignment, cmap = custom_cmap, center=0, annot=True, yticklabels = MyData.ID_stud, xticklabels = MyData.ID_school)\n",
    "        p.set_xlabel(\"Students\", fontsize = 15)\n",
    "        p.set_ylabel(\"Schools\", fontsize = 15)\n",
    "        name = path + self.file_name + \"/\" + self.label + \".pdf\"\n",
    "        p.set_title(self.label, fontsize = 20)\n",
    "        plt.savefig(name, format=\"pdf\", bbox_inches=\"tight\")\n",
    "        \n",
    "        # Assignment, ranked by preference\n",
    "        plt.figure()\n",
    "\n",
    "        # Create a custom colormap (to show negative values red)\n",
    "        colors = [\"red\", \"white\", \"green\"]  # Red for negatives, white for 0, blue for positives\n",
    "        custom_cmap2 = LinearSegmentedColormap.from_list(\"CustomMap\", colors)\n",
    "        \n",
    "        # Create the heatmap\n",
    "        sns.set(rc = {'figure.figsize':(MyData.n_stud,MyData.n_schools/1.5)})\n",
    "        p = sns.heatmap(self.assignment_ranked, cmap = custom_cmap2, center=0, annot=True, yticklabels = MyData.ID_stud, xticklabels = range(1,MyData.n_schools + 1))\n",
    "        p.set_xlabel(\"Preference\", fontsize = 15)\n",
    "        p.set_ylabel(\"Students\", fontsize = 15)\n",
    "        name = path + self.file_name + \"/\" + self.label + \"_Ranked.pdf\"\n",
    "        title = self.file_name + \": ranked by decreasing preference\"\n",
    "        p.set_title(title, fontsize = 20)\n",
    "        plt.savefig(name, format=\"pdf\", bbox_inches=\"tight\")\n",
    "        \n",
    "        plt.figure()\n",
    "    \n",
    "    # Save the assignment to the correct subdirectory\n",
    "    def export_assignment(self):\n",
    "        if os.path.exists(\"Results\") == False:\n",
    "            # If not, create folder\n",
    "            os.makedirs(\"Results\")\n",
    "\n",
    "        s = os.path.join(\"Results\", \"Assignments\")\n",
    "        if os.path.exists(s) == False:\n",
    "            # If not, create folder\n",
    "            os.makedirs(s)\n",
    "\n",
    "        s = os.path.join(\"Results\", \"Assignments\",self.file_name)\n",
    "        if os.path.exists(s) == False:\n",
    "            os.makedirs(s)\n",
    "        \n",
    "        name = \"Results/Assignments/\" + self.file_name + \"/\" + self.label + \"_\" + self.file_name + \".csv\"\n",
    "        np.savetxt(name, self.assignment, delimiter=\",\")\n",
    "        \n",
    "    # Choose what is being shown for the command 'print(Sol)', where 'Sol' is an instance of the class 'Assignment'\n",
    "    def __str__(self):\n",
    "        \n",
    "        return s\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff12e4b-8541-4f54-a018-32e444307c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model: \n",
    "    \"\"\"\n",
    "    Contains two methods:\n",
    "        __init__: initializes the model, and the solver environment\n",
    "\n",
    "        Solve: solves the model.\n",
    "            The parameters of this method can control which objective function is optimized, and which solver is used\n",
    "    \"\"\"\n",
    "    \n",
    "    # Used this example as a template for Pulp: https://coin-or.github.io/pulp/CaseStudies/a_sudoku_problem.html\n",
    "    \n",
    "    def __init__(self, MyData: Data, p: Assignment, print_out: bool, nr_matchings = -1):\n",
    "        \"\"\"\n",
    "        Initialize an instance of Model.\n",
    "\n",
    "        Args:\n",
    "            MyData (type: Data): instance of class Data.\n",
    "            p (type: Assignment): instance of class Assignment.\n",
    "            print_out (type: bool): boolean that controls which output is printed.\n",
    "            nr_matchings (optional): number of matchings used in the decomposition, optional parameter that defaults to n_students * n_schools + 1\n",
    "\n",
    "        \"\"\"\n",
    "        # 'nr_matchings' refers to number of matchings used to find decomposition\n",
    "        self.MyData = copy.deepcopy(MyData)\n",
    "        self.p = copy.deepcopy(p)\n",
    "        self.nr_matchings = nr_matchings\n",
    "        if nr_matchings == -1:\n",
    "            self.nr_matchings = self.MyData.n_stud * self.MyData.n_schools + 1\n",
    "\n",
    "        # Create the pulp model\n",
    "        self.model = LpProblem(\"Improving_ex_post_stable_matchings\", LpMinimize)\n",
    "\n",
    "        # Create variables to store the solution in\n",
    "        self.Xdecomp = [] # Matchings in the found decomposition\n",
    "        self.Xdecomp_coeff = [] # Weights of these matchings\n",
    "        zero = np.zeros(shape=(self.MyData.n_stud, self.MyData.n_schools))\n",
    "        self.Xassignment = Assignment(MyData, zero) # Contains the final assignment found by the model\n",
    "\n",
    "        #### DECISION VARIABLES ####\n",
    "        self.STUD = range(0,self.MyData.n_stud)\n",
    "        self.SCHOOLS = range(0, self.MyData.n_schools)\n",
    "        self.N_MATCH = range(0, self.nr_matchings)\n",
    "\n",
    "        # Tuple with all student-school pairs that are preferred to outside option\n",
    "        # This tuple contains the INDICES of the students and the pairs, and not their original names\n",
    "        self.PAIRS = []\n",
    "        for i in range(0, MyData.n_stud):\n",
    "            for j in range(0,len(MyData.pref[i])):\n",
    "        \n",
    "                # Convert pref[i][k] (school ID as string) to column index\n",
    "                col_index = int(MyData.pref[i][j]) - 1\n",
    "                self.PAIRS.append((i,col_index))              \n",
    "        \n",
    "        # M[k][i][j] = 1 if student i is assigned to school j in matching k, and 0 otherwise\n",
    "        self.M = LpVariable.dicts(\"M\", [(k, i, j) for k in self.N_MATCH for i, j in self.PAIRS], cat=\"Binary\")\n",
    "\n",
    "        # Auxiliary variables to avoid non-linearity\n",
    "        self.z = LpVariable.dicts(\"z\", [(k, i, j) for k in self.N_MATCH for (i, j) in self.PAIRS], 0, 1)\n",
    "\n",
    "        # Rename M and z\n",
    "        for k, i, j in self.M:\n",
    "            student_name = self.MyData.ID_stud[i]\n",
    "            school_name = self.MyData.ID_school[j]\n",
    "            self.M[k, i, j].name = f\"M_{k}_{student_name}_{school_name}\"\n",
    "            self.z[k, i, j].name = f\"z_{k}_{student_name}_{school_name}\"\n",
    "\n",
    "        # Q[i][j] is the new probability with which student i is assigned to school j, lies between 0 and 1\n",
    "        self.Q = LpVariable.dicts(\"q\", self.PAIRS, 0, 1) \n",
    "    \n",
    "        # w[k] is the weight of matching k in the decomposition\n",
    "        self.w = LpVariable.dicts(\"w\", self.N_MATCH, 0, 1)\n",
    "\n",
    "        #### OBJECTIVE FUNCTION ####\n",
    "            # Done separately in other functions (see function Solve)\n",
    "        \n",
    "            \n",
    "        #### CONSTRAINTS ####\n",
    "        # Other constraints defined for specific models in functions below (see function Solve)\n",
    "        \n",
    "        # Stability\n",
    "        for k in self.N_MATCH:\n",
    "            for i in self.STUD:\n",
    "                for j in range(len(self.MyData.pref_index[i])):\n",
    "                    current_school = self.MyData.pref_index[i][j]\n",
    "                    lin = LpAffineExpression()\n",
    "\n",
    "                    lin += self.M[k, i, current_school]\n",
    "\n",
    "                    # Add all schools that are at least as preferred as the j-ranked school by student i\n",
    "                    for l in range(j):\n",
    "                        lin += self.MyData.cap[current_school] * self.M[k,i,self.MyData.pref_index[i][l]]\n",
    "\n",
    "\n",
    "                    # Add terms based on priorities\n",
    "                    prior_current = self.MyData.rank_prior[current_school][i]\n",
    "                    for s in self.STUD:\n",
    "                        if s != i:\n",
    "                            # If current_school ranks student s higher than student i\n",
    "                            if self.MyData.rank_prior[current_school][s] <= self.MyData.rank_prior[current_school][i]:\n",
    "                                if (s, current_school) in self.PAIRS:\n",
    "                                    lin += self.M[k,s,current_school]\n",
    "\n",
    "                    # Add to model:\n",
    "                    name = \"STAB_\" + str(k) + \"_\" + self.MyData.ID_stud[i] + \"_\" + self.MyData.ID_school[current_school] \n",
    "                    self.model += (lin >= self.MyData.cap[current_school], name) \n",
    "\n",
    "        \n",
    "        # Each student at most assigned to one school\n",
    "        for l in self.N_MATCH:\n",
    "            for i in self.STUD:\n",
    "                self.model += lpSum([self.M[l,i,j] for j in self.SCHOOLS if (i,j) in self.PAIRS]) <= 1, f\"LESS_ONE_{l,i}\"\n",
    "\n",
    "        # Capacities schools respected\n",
    "        for l in self.N_MATCH:\n",
    "            for j in self.SCHOOLS:\n",
    "                self.model += lpSum([self.M[l,i,j] for i in self.STUD if (i,j) in self.PAIRS]) <= self.MyData.cap[j], f\"LESS_CAP_{l,j}\"\n",
    "                                    \n",
    "\n",
    "    def Solve(self, obj: str, solver: str, print_out: bool):\n",
    "        \"\"\"\n",
    "        Solves the formulation.\n",
    "        Returns an instance from the Assignment class.\n",
    "\n",
    "        Args:\n",
    "            obj (str): controls the objective function\n",
    "                \"IMPR_RANK\": minimizes expected rank while maintaining ex-post stability\n",
    "                \"STABLE\": maximizes fraction of stable matchings in decomposition\n",
    "            solver (str): controls which solver is used. See options through following commands:\n",
    "                solver_list = pl.listSolvers(onlyAvailable=True)\n",
    "                print(solver_list)\n",
    "            print_out (bool): boolean that controls which output is printed.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Check that strings-arguments are valid\n",
    "\n",
    "        # Valid values for 'solver'\n",
    "        solver_list = pl.listSolvers(onlyAvailable=True)\n",
    "        if solver not in solver_list:\n",
    "           raise ValueError(f\"Invalid value: '{solver}'. Allowed values are: {solver_list}\")\n",
    "\n",
    "        # Valid values for 'obj'\n",
    "        obj_list = [\"IMPR_RANK\", \"STABLE\"]\n",
    "        if obj not in obj_list:\n",
    "           raise ValueError(f\"Invalid value: '{obj}'. Allowed values are: {obj_list}\")\n",
    "\n",
    "        #### FORMULATION ####\n",
    "        \n",
    "        # Set the objective function\n",
    "        if obj == \"IMPR_RANK\":\n",
    "            self.Improve_rank(print_out)\n",
    "        \n",
    "        elif obj == \"STABLE\":\n",
    "            self.Max_Stable_Fraction(print_out)\n",
    "\n",
    "        self.model.writeLP(\"Test.lp\")\n",
    "\n",
    "        \n",
    "        #### SOLVE ####\n",
    "            \n",
    "        # String can't be used as the argument in solve method, so convert it like this:\n",
    "        solver_function = globals()[solver]  # Retrieves the GUROBI function or class\n",
    "        \n",
    "        # Solve the formulation\n",
    "        self.model.solve(solver_function())\n",
    "        \n",
    "        #### STORE SOLUTION ####\n",
    "        # Make sure assignment is empty in Xassignment\n",
    "        self.Xassignment.assignment = np.zeros(shape=(self.MyData.n_stud, self.MyData.n_schools))\n",
    "\n",
    "        for (i,j) in self.PAIRS:\n",
    "            self.Xassignment.assignment[i,j] = self.Q[i,j].varValue\n",
    "\n",
    "        # Store decomposition\n",
    "        self.Xdecomp = [] # Matchings in the found decomposition\n",
    "        self.Xdecomp_coeff = [] # Weights of these matchings\n",
    "\n",
    "        for l in self.N_MATCH:\n",
    "            self.Xdecomp.append(np.zeros(shape=(self.MyData.n_stud, self.MyData.n_schools)))\n",
    "            self.Xdecomp_coeff.append(self.w[l].varValue)\n",
    "            for (i,j) in self.PAIRS:\n",
    "                self.Xdecomp[-1][i,j] = self.M[l,i,j].varValue\n",
    "                \n",
    "        return self.Xassignment\n",
    "\n",
    "\n",
    "    def Improve_rank(self, print_out: str):\n",
    "        \"\"\"\n",
    "        Creates and solves formulation to minimize the expected rank while ensuring the found random matching is ex-post stable.\n",
    "        \"\"\"\n",
    "        \n",
    "        if print_out == True:\n",
    "            # Compute average rank of current assignment\n",
    "\n",
    "            sum = 0\n",
    "            for (i,j) in self.PAIRS:\n",
    "                sum += self.p[i,j] * (self.MyData.rank_pref[i,j] + 1) # + 1 because the indexing starts from zero\n",
    "            # Average\n",
    "            sum = sum/self.MyData.n_stud\n",
    "            print(f\"\\nAverage rank before optimization: {sum}.\\n\\n\")\n",
    "        \n",
    "        # Objective function\n",
    "        lin = LpAffineExpression()\n",
    "        for (i,j) in self.PAIRS:\n",
    "            lin += (self.Q[i,j] * (self.MyData.rank_pref[i,j] + 1)) / self.MyData.n_stud # + 1 because the indexing starts from zero\n",
    "        self.model += lin\n",
    "\n",
    "        # Define q based on matchings in decomposition\n",
    "            # Where z is an auxiliary variable to avoid non-linearities\n",
    "        for l in self.N_MATCH:\n",
    "            for (i,j) in self.PAIRS:\n",
    "                self.model += self.z[l, i, j] - self.w[l] <= 0,f\"z_w{l,i,j}\" \n",
    "\n",
    "        for l in self.N_MATCH:\n",
    "            for (i,j) in self.PAIRS:\n",
    "                self.model += self.z[l, i, j] - self.M[l, i, j] <= 0,f\"z_M_{l, i, j}\"\n",
    "\n",
    "        for l in self.N_MATCH:\n",
    "            for (i,j) in self.PAIRS:\n",
    "                self.model += self.z[l, i, j] + (1 - self.M[l, i, j]) - self.w[l]  >= 0,f\"z_w_M_{l, i, j}\"\n",
    "                # Maybe these constraints are redundant because of the objective function\n",
    "\n",
    "        for (i,j) in self.PAIRS:\n",
    "            self.model += lpSum([self.z[l, i, j] for l in self.N_MATCH]) == self.Q[i,j], f\"z_Q_{i, j}\"\n",
    "\n",
    "        # Ensure weights sum up to one\n",
    "        self.model += lpSum([self.w[l] for l in self.N_MATCH]) == 1, f\"SUM_TO_ONE\"\n",
    "\n",
    "        # First-order stochastic stability\n",
    "        for i in self.STUD:\n",
    "            for j in range(len(self.MyData.pref[i])):\n",
    "                lin = LpAffineExpression()\n",
    "                for k in range(j+1):\n",
    "                    pref_school = self.MyData.pref_index[i][k]\n",
    "                    lin += self.Q[i,pref_school]\n",
    "                    lin -= self.p[i,pref_school]\n",
    "                name = \"FOSD_\" +  self.MyData.ID_stud[i] + \"_\" + str(j)\n",
    "                self.model += (lin >= 0, name)\n",
    "\n",
    "\n",
    "    def Max_Stable_Fraction(self, print_out: str):\n",
    "        # Objective function\n",
    "        obj = LpAffineExpression()\n",
    "        for l in self.N_MATCH:\n",
    "            obj += self.w[l] \n",
    "        self.model += obj\n",
    "        self.model.sense = LpMaximize\n",
    "\n",
    "        # Constraints to ensure that decomposition is at least equal to p (element-wise)\n",
    "            # Where z is an auxiliary variable to avoid non-linearities\n",
    "        for l in self.N_MATCH:\n",
    "            for (i,j) in self.PAIRS:\n",
    "                self.model += self.z[l, i, j] - self.w[l] <= 0,f\"z_w{l,i,j}\" \n",
    "\n",
    "        for l in self.N_MATCH:\n",
    "            for (i,j) in self.PAIRS:\n",
    "                self.model += self.z[l, i, j] - self.M[l, i, j] <= 0,f\"z_M_{l, i, j}\"\n",
    "\n",
    "        for l in self.N_MATCH:\n",
    "            for (i,j) in self.PAIRS:\n",
    "                self.model += self.z[l, i, j] + (1 - self.M[l, i, j]) - self.w[l]  >= 0,f\"z_w_M_{l, i, j}\"\n",
    "                # Maybe these constraints are redundant because of the objective function\n",
    "\n",
    "        for (i,j) in self.PAIRS:\n",
    "            self.model += lpSum([self.z[l, i, j] for l in self.N_MATCH]) == self.Q[i,j], f\"z_Q_{i, j}\"\n",
    "\n",
    "        for (i,j) in self.PAIRS:\n",
    "            self.model += lpSum([self.z[l, i, j] for l in self.N_MATCH]) <= self.p[i,j], f\"z_p_{i, j}\"\n",
    "        \n",
    "\n",
    "    def print_solution(self):\n",
    "        s = \"The obtained random matching is:\\n\"\n",
    "        s+=f\"\\t\\t\"\n",
    "        for j in self.SCHOOLS:\n",
    "            s+=f\"{self.MyData.ID_school[j]}\\t\"\n",
    "        s+=\"\\n\"\n",
    "        for i in self.STUD:\n",
    "            s+= f\"\\t{self.MyData.ID_stud[i]}\\t\"\n",
    "            for j in self.SCHOOLS:\n",
    "                s+=f\"{self.Xassignment.assignment[i,j]}\\t\"\n",
    "            s+=f\"\\n\"\n",
    "        s+=f\"\\n\"\n",
    "\n",
    "        s+= \"The matchings with positive weights are:\\n\"\n",
    "\n",
    "        for l in self.N_MATCH:\n",
    "            if self.Xdecomp_coeff[l] > 0:\n",
    "                s+=f\"\\t w[{l}] = {self.Xdecomp_coeff[l]}\\n\"\n",
    "                for i in self.STUD:\n",
    "                    s+=f\"\\t\\t\"\n",
    "                    for j in self.SCHOOLS:\n",
    "                        if self.Xdecomp[l][i,j] == 1:\n",
    "                            s+=f\"1\\t\"\n",
    "                        else:\n",
    "                            s+= f\"0\\t\"\n",
    "                    s+=f\"\\n\"\n",
    "                s+=f\"\\n\"\n",
    "        print(s)\n",
    "\n",
    "        \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6de866b-7763-4047-a82a-c73dbd6d94bd",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fb65c44-c427-4dcb-b5cc-0c92ec926ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenParam:\n",
    "    # Parameters to used for data generation, see https://github.com/DemeulemeesterT/GOSMI\n",
    "    \n",
    "    def __init__(self, capacity_ratio=1.2, corr_cap_pop=0.21, mean_pref=2.42, sigma_pref=1.05, \n",
    "                 CV_cap=0.8, CV_pop=0.6, delta_1=0.14, delta_2=0.009, pop_percentage=0.10):\n",
    "        self.capacity_ratio = capacity_ratio\n",
    "        self.corr_cap_pop = corr_cap_pop\n",
    "        self.mean_pref = mean_pref\n",
    "        self.sigma_pref = sigma_pref\n",
    "        self.CV_cap = CV_cap\n",
    "        self.CV_pop = CV_pop\n",
    "        self.delta_1 = delta_1\n",
    "        self.delta_2 = delta_2\n",
    "        self.pop_percentage = pop_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56801ed6-ee53-4c64-9a39-0864afb98226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_students: int, n_schools: int, parameters: DataGenParam, name: str, print_data=False, seed=123456789):\n",
    "    \"\"\"\n",
    "    Generate data. The preferences and capacities are based on: https://github.com/DemeulemeesterT/GOSMI\n",
    "\n",
    "    Parameters:\n",
    "    - n_students: Number of students.\n",
    "    - n_schools: Number of schools.\n",
    "    - parameters: An instance of DataGenParam with generation parameters.\n",
    "    - print_data: Whether to print the generated data.\n",
    "    - seed: Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - An object of the class Data\n",
    "    \"\"\"\n",
    "    if seed != 123456789:\n",
    "        # Use seed in argument\n",
    "        rng = default_rng(seed)\n",
    "    else:\n",
    "        # Generate random seed \n",
    "        # Create a seed based on the current time\n",
    "        seed = int(time.time() * 1000) % (2**32)  # Modulo 2^32 to ensure it's a valid seed\n",
    "\n",
    "    # Initialize arrays\n",
    "    students = list(range(n_students))\n",
    "    schools = list(range(n_schools))\n",
    "\n",
    "    # Generate capacities and popularity\n",
    "    capacity_total = int(round(parameters.capacity_ratio * n_students))\n",
    "    capacity_aid = rng.normal(0, 1, n_schools)\n",
    "    popularity_aid = rng.normal(0, 1, n_schools)\n",
    "    \n",
    "    # Cholesky decomposition for correlated random variables\n",
    "    covar = np.array([\n",
    "        [1, parameters.corr_cap_pop],\n",
    "        [parameters.corr_cap_pop, 1]\n",
    "    ])\n",
    "    G = np.linalg.cholesky(covar).T\n",
    "    correlated = G @ np.vstack((capacity_aid, popularity_aid))\n",
    "    capacity_aid, popularity_aid = correlated[0], correlated[1]\n",
    "\n",
    "    # Rescale capacities\n",
    "    mean_capacity_aid = np.mean(capacity_aid)\n",
    "    capacities = np.round((capacity_total / n_schools) * \n",
    "                          (1 + parameters.CV_cap * (capacity_aid - mean_capacity_aid)))\n",
    "    capacities = np.clip(capacities, 1, None).astype(int)  # Ensure no capacity < 1\n",
    "    scale_factor = capacity_total / np.sum(capacities)\n",
    "    capacities = np.round(capacities * scale_factor).astype(int)\n",
    "\n",
    "    # Generate preference lengths\n",
    "    pref_lengths = rng.normal(parameters.mean_pref, parameters.sigma_pref, n_students)\n",
    "    pref_lengths = np.clip(pref_lengths, 1, n_schools).astype(int)\n",
    "\n",
    "    # Determine popularity thresholds\n",
    "    mean_pop_ratio = np.sum(pref_lengths) / np.sum(capacities)\n",
    "    mean_popularity_aid = np.mean(popularity_aid)\n",
    "    popularity_aid = mean_pop_ratio * (1 + parameters.CV_pop * (popularity_aid - mean_popularity_aid))\n",
    "    popularity_aid = np.clip(popularity_aid, 0.2, None)  # Ensure no popularity < 0.2\n",
    "    requests = capacities * popularity_aid\n",
    "    popularity_aid *= np.sum(pref_lengths) / np.sum(requests)\n",
    "\n",
    "    # Define popular schools\n",
    "    sorted_indices = np.argsort(-popularity_aid)\n",
    "    popularity_threshold = popularity_aid[sorted_indices[int(parameters.pop_percentage * n_schools)]]\n",
    "    popular = popularity_aid > popularity_threshold\n",
    "\n",
    "    # Generate preferences for each student\n",
    "    preferences = []\n",
    "    for i in range(n_students):\n",
    "        student_pref = []\n",
    "        available_schools = list(range(n_schools))\n",
    "        for _ in range(pref_lengths[i]):\n",
    "            weights = popularity_aid[available_schools]\n",
    "            weights /= np.sum(weights)\n",
    "            choice = rng.choice(available_schools, p=weights)\n",
    "            student_pref.append(choice) \n",
    "            available_schools.remove(choice)\n",
    "        preferences.append(student_pref)\n",
    "\n",
    "    # Generate random school priorities:\n",
    "    # For now, just simply\n",
    "        # Randomly order students for each school\n",
    "        # Divide into three indifference groups for each school\n",
    "\n",
    "    priorities = []\n",
    "    for j in range(n_schools):\n",
    "        permutation = np.random.permutation(students)\n",
    "\n",
    "        # Split the list into three roughly equal groups\n",
    "        group_size = len(permutation) // 3\n",
    "        group1 = permutation[:group_size]\n",
    "        group2 = permutation[group_size:2 * group_size]\n",
    "        group3 = permutation[2 * group_size:]\n",
    "\n",
    "        priorities.append([tuple(group1), tuple(group2), tuple(group3)])\n",
    "    \n",
    "    # Optionally print data\n",
    "    if print_data:\n",
    "        print(f\"Generated data with {n_students} students and {n_schools} schools.\")\n",
    "        print(f\"Preferences: {preferences}\")\n",
    "        print(f\"Priorities: {priorities}\")\n",
    "        print(f\"Capacities: {list(capacities)}\")\n",
    "        # print(f\"Popularity Ratios: {list(popularity_aid)}\")\n",
    "        print(f\"Students: {students}\")\n",
    "        print(f\"Schools: {schools}\")\n",
    "    \n",
    "    MyData = Data(n_students, n_schools, preferences, priorities, capacities, students, schools, name)\n",
    "    \n",
    "    # Return results\n",
    "    return MyData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487fab23-882b-4739-8e03-3f2fa56bd10d",
   "metadata": {},
   "source": [
    "## Gale-Shapley algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "ce62dd6c-6546-4fdb-80bf-845a70b8f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gale_shapley(MyData: Data):\n",
    "    \"\"\"\n",
    "    Gale-Shapley algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    - An instance from the Data class\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array containing the assignment\n",
    "    \"\"\"\n",
    "    n_stud = len(MyData.pref)\n",
    "    n_schools = len(MyData.prior)\n",
    "    pref = copy.deepcopy(MyData.pref) # We will gradually delete preferences from this \n",
    "\n",
    "    # Initialize data structures\n",
    "    free_stud = list(range(n_stud))  # List of free students by index\n",
    "    # Initialize temp_assigned with empty lists for each school\n",
    "    temp_assigned = {school_index: [] for school_index in range(len(MyData.cap))} \n",
    "\n",
    "    while free_stud:\n",
    "        # First we go through all students in 'free_stud' and remove them from the list\n",
    "        while free_stud:\n",
    "            i = free_stud[0]  # Get the first student\n",
    "            free_stud.pop(0)  # Remove it\n",
    "            # Assign free students to their most preferred school among remaining choices...\n",
    "            # ... if preference list not empty yet\n",
    "            if len(pref[i])>0:\n",
    "                # Find index of that school\n",
    "                index = MyData.ID_school.index(pref[i][0])\n",
    "                temp_assigned[index].append(i) \n",
    "    \n",
    "                # Remove that school from student i's preferences\n",
    "                pref[i].pop(0)\n",
    "\n",
    "        # Now each school j only keeps cap[j] most preferred students, and the others will be added to free_stud again\n",
    "        for j in range(n_schools):\n",
    "            if len(temp_assigned[j]) > MyData.cap[j]:\n",
    "                # Dictionary containing priorities of the students who are temporarily assigned to school j\n",
    "                prior_values = {stud_index: [] for stud_index in temp_assigned[j]}  \n",
    "                for i in range(len(temp_assigned[j])):\n",
    "                    # Find the position of student temp_assigned[j][i] in the priority list of school j\n",
    "                    prior_values[temp_assigned[j][i]] = MyData.prior[j].index(MyData.ID_stud[temp_assigned[j][i]])\n",
    "\n",
    "                # Sort the dictionary prior_values items by value\n",
    "                sorted_prior_values = sorted(prior_values.items(), key=lambda item: item[1])\n",
    "\n",
    "                # Remove the least preferred students who exceed capacity, and add them to free_students\n",
    "                while len(temp_assigned[j]) > MyData.cap[j]:\n",
    "                    # Add to free_stud\n",
    "                    free_stud.append(sorted_prior_values[MyData.cap[j]][0])\n",
    "\n",
    "                    # Remove from temp_assigned\n",
    "                    temp_assigned[j].remove(sorted_prior_values[MyData.cap[j]][0])\n",
    "                    #temp_assigned[j].pop(MyData.cap[j])\n",
    "\n",
    "    # Finally, transform the assignment in a numpy array where M[i][j] = 1 if student i is assigned to school j\n",
    "    M = np.zeros(shape=(n_stud, n_schools))\n",
    "    for j in range(n_schools):\n",
    "        for k in range(len(temp_assigned[j])):\n",
    "            M[temp_assigned[j][k]][j] = 1\n",
    "    \n",
    "    return M\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6888de94-f4fe-475e-855a-69b294772cfa",
   "metadata": {},
   "source": [
    "## Sample Deferred Acceptance with tie-breaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "7bac68da-5dc3-4649-a756-3d716efa51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DA_STB(MyData: Data, n_iter: int, seed = 123456789, print_out = False):\n",
    "    \"\"\"\n",
    "    Deferred Acceptance with single tie-breaking\n",
    "\n",
    "    Parameters:\n",
    "    - MyData: An instance from the Data class\n",
    "    - n_iter: number of tie-breakings sampled\n",
    "    - print_out: boolean to control output on the screen\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array containing the random matching\n",
    "    \"\"\"\n",
    "\n",
    "    if seed != 123456789:\n",
    "        # Use seed in argument\n",
    "        rng = default_rng(seed)\n",
    "    else:\n",
    "        # Generate random seed \n",
    "        # Create a seed based on the current time\n",
    "        seed = int(time.time() * 1000) % (2**32)  # Modulo 2^32 to ensure it's a valid seed\n",
    "\n",
    "    # First, check how many tie-breaking rules would be needed in total\n",
    "    # Look at total number of students who are included in ties\n",
    "    students_in_ties = set()\n",
    "    for j in range(MyData.n_schools):\n",
    "        for k in range(len(MyData.prior[j])):\n",
    "            if len(MyData.prior[j][k]) >= 2: # When more than a single student in this element\n",
    "                for l in range(len(MyData.prior[j][k])):\n",
    "                    # students_in_ties.add(MyData.ID_stud.index(MyData.prior[j][k][l])) # We add the index of this student, not its name\n",
    "                    students_in_ties.add(MyData.prior[j][k][l])\n",
    "\n",
    "    students_in_ties = list(students_in_ties) # Convert the set to a list, allows us to access k-th element\n",
    "    \n",
    "    # The total number of needed tie-breaking rules is m!, where m = |student_in_ties|\n",
    "    n_STB = math.factorial(len(students_in_ties))\n",
    "\n",
    "    # We only need to perturb the students who appear in ties:\n",
    "    \n",
    "    if n_STB < n_iter:\n",
    "        n_iter = n_STB\n",
    "        # Enumerate all relevant permutations\n",
    "        permut = list(itertools.permutations(students_in_ties))\n",
    "    else:\n",
    "        permut = set() # We first create a set, to ensure that all found permutations are unique. Later, convert to list\n",
    "        # Sample n_iter out of all n_STB relevant permutations\n",
    "        while len(permut) < n_iter:\n",
    "            np.random.shuffle(students_in_ties)  # Shuffle in place\n",
    "            permut.add(tuple(students_in_ties))\n",
    "        permut = list(permut)\n",
    "    \n",
    "    if print_out:\n",
    "        print(f\"Students in ties: {len(students_in_ties)}\")\n",
    "        print(f\"Tie-breaking rules needed: {n_STB}\")\n",
    "        print(f\"Tie-breaking rules sampled: {n_iter}\")\n",
    "        #print(f\"permut: {permut}\")\n",
    "\n",
    "    # For each of the permutations, break ties in the preferences and run Gale-Shapley algorithm on them\n",
    "    M_sum = np.zeros(shape=(MyData.n_stud, MyData.n_schools)) # Will contain the final random_assignment\n",
    "\n",
    "    for p in permut:\n",
    "        prior_new = [] \n",
    "        for j in range(len(MyData.prior)):\n",
    "            # Just add priorities if no ties:\n",
    "            if len(MyData.prior[j]) == MyData.n_stud:\n",
    "                prior_new.append(MyData.prior[j])\n",
    "            else:\n",
    "                prior_array = []\n",
    "                for k in range(len(MyData.prior[j])):\n",
    "                    if len(MyData.prior[j][k]) == 1:\n",
    "                        prior_array.append(MyData.prior[j][k])\n",
    "                    else: # set of students who have same priorities\n",
    "                        # Reorder the students based on the permuation\n",
    "                        reordered_prior = list(sorted(MyData.prior[j][k], key=lambda x: p.index(x)))\n",
    "\n",
    "                        # Add to prior_array\n",
    "                        for l in range(len(MyData.prior[j][k])):\n",
    "                            prior_array.append(reordered_prior[l])\n",
    "                prior_new.append(prior_array)\n",
    "                \n",
    "        # Compute DA matching for the new priorities after tie-breaking\n",
    "        Data_new_prior = Data(MyData.n_stud, MyData.n_schools, MyData.pref, prior_new, MyData.cap, MyData.ID_stud, MyData.ID_school, MyData.file_name)\n",
    "        M_sum = M_sum + gale_shapley(Data_new_prior)            \n",
    "        \n",
    "    M_sum = M_sum / n_iter\n",
    "\n",
    "    return M_sum\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774362ba-1144-48c7-a256-1e069931ea82",
   "metadata": {},
   "source": [
    "## Initialize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "54562267-7331-4872-b035-feb815c48d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preferences of the students\n",
    "# 'pref[i][k]' contains the position of the k-th ranked school in the preferences.\n",
    "# We assume the preferences to be strict\n",
    "# Note that preferences can be strict. We indicate this by a tuple () in the list.\n",
    "\n",
    "# Example paper\n",
    "n_stud = 4\n",
    "n_schools = 4\n",
    "\n",
    "file_name = \"Ex_paper\"\n",
    "\n",
    "# Preferences students\n",
    "pref = [['1', '3', '4', '2'],\n",
    "       ['1','4','3','2'],\n",
    "       # ['1', '4'],\n",
    "       ['2','3', '4', '1'],\n",
    "       #['2', '4', '3', '1']]\n",
    "        ['2', '4', '1', '3']]\n",
    "\n",
    "# Priorities schools\n",
    "prior = [[('A', 'B'), 'C', 'D'],\n",
    "        [('C', 'D'), 'A', 'B'],\n",
    "        ['B', 'D', ('A', 'C')],\n",
    "        ['A', 'C', ('B', 'D')]]\n",
    "#prior = [['D', 'A', 'B', 'C'],\n",
    "#        ['C', 'D', 'A', 'B'],\n",
    "#        ['B', 'D', 'A', 'C'],\n",
    "#        ['A', 'C', 'B', 'D']]\n",
    "\n",
    "\n",
    "# Capacities schools\n",
    "cap = [1,1,1,1]\n",
    "\n",
    "# Names of students and schools\n",
    "ID_stud = [\"A\", \"B\", \"C\", \"D\"]\n",
    "ID_school = [\"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "# Also create the random matching upon which we want to improve\n",
    "p = np.zeros(shape=(n_stud, n_schools))\n",
    "p[0][0] = 1/2\n",
    "p[1][0] = 1/2\n",
    "p[2][1] = 1/2\n",
    "p[3][1] = 1/2\n",
    "p[0][2] = 3/8\n",
    "p[2][2] = 3/8\n",
    "p[1][3] = 3/8\n",
    "p[3][3] = 3/8\n",
    "p[0][3] = 1/8\n",
    "p[2][3] = 1/8\n",
    "p[1][2] = 1/8\n",
    "p[3][2] = 1/8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2713baa0-f0ab-4efe-b12e-a56acbff26d4",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "c9c1abf4-9d79-462c-823f-55973799314f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data with 10 students and 10 schools.\n",
      "Preferences: [[8, 3, 1], [8, 5, 3, 6, 9], [9, 3, 6], [3, 7, 4, 5], [9, 1, 6, 0], [9, 7, 1, 8], [0, 5, 1], [5, 8, 1], [0, 5, 3], [1, 7, 4, 8]]\n",
      "Priorities: [[(3, 5, 1), (7, 8, 0), (4, 2, 9, 6)], [(5, 7, 3), (1, 8, 4), (6, 2, 9, 0)], [(8, 9, 7), (5, 2, 3), (1, 0, 4, 6)], [(3, 5, 8), (0, 7, 4), (1, 9, 6, 2)], [(4, 2, 6), (7, 0, 8), (5, 3, 9, 1)], [(4, 5, 3), (2, 7, 8), (0, 6, 9, 1)], [(9, 2, 0), (3, 5, 8), (7, 6, 1, 4)], [(8, 7, 9), (2, 4, 3), (5, 1, 6, 0)], [(8, 3, 0), (6, 9, 7), (2, 1, 4, 5)], [(3, 4, 0), (7, 6, 1), (8, 5, 2, 9)]]\n",
      "Capacities: [1, 1, 1, 1, 1, 1, 2, 2, 1, 1]\n",
      "Students: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Schools: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "parameters = DataGenParam(mean_pref = 4) # Default parameters\n",
    "MyData = generate_data(n_students=10, n_schools=10, parameters = parameters, name=\"Test_DataGen\", print_data=True, seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "b33c068f-ccc4-40f1-af2a-e270e5902b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data instance has the following properties: \n",
      "\n",
      "\t4 students.\n",
      "\t4 schools. \n",
      "\n",
      " \tPREFERENCES:\n",
      "\tA\t1 3 4 2 \n",
      "\tB\t1 4 3 2 \n",
      "\tC\t2 3 4 1 \n",
      "\tD\t2 4 1 3 \n",
      "\n",
      "\n",
      " \tCAPACITIES & PRIORITIES:\n",
      "\t1\t1\t{A B} C D \n",
      "\t2\t1\t{C D} A B \n",
      "\t3\t1\tB D {A C} \n",
      "\t4\t1\tA C {B D} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "MyData = Data(n_stud, n_schools, pref, prior, cap, ID_stud, ID_school, file_name)\n",
    "print(MyData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43896c1d-d24f-4bda-a240-a9859d3b66e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m A \u001b[38;5;241m=\u001b[39m Assignment(MyData, p, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEx_paper\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# To visualize assignment\u001b[39;00m\n\u001b[0;32m      4\u001b[0m A\u001b[38;5;241m.\u001b[39mvisualize()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "A = Assignment(MyData, p, \"Ex_paper\")\n",
    "\n",
    "# To visualize assignment\n",
    "A.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fc5a49-fd8b-49e9-bcd6-5b95112b9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModel = Model(MyData, p, True)\n",
    "#q = MyModel.Solve(\"IMPR_RANK\", \"GUROBI\", True)\n",
    "q = MyModel.Solve(\"STABLE\", \"GUROBI\", True)\n",
    "\n",
    "# The problem is solved using PuLP's choice of Solver\n",
    "# MyModel.model.solve(GUROBI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3baa5c-1f4f-4aaf-9124-b7a0e830cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModel.print_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5fd6dc-54ee-4926-ae1d-57b0e7982182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the solution\n",
    "q.visualize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a5f22f-3855-4346-bd03-4ee5ce105d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asses the difference\n",
    "diff = Assignment(MyData, q.assignment - p, \"Ex_paper_Diff\")\n",
    "diff.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "41f8f9e4-b294-492a-bce2-b6a409b04c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(gale_shapley(MyData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "5e8e77cd-46ac-417a-8f2b-772c3f5dc315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students in ties: 4\n",
      "Tie-breaking rules needed: 24\n",
      "Tie-breaking rules sampled: 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5  , 0.   , 0.375, 0.125],\n",
       "       [0.5  , 0.   , 0.125, 0.375],\n",
       "       [0.   , 0.5  , 0.375, 0.125],\n",
       "       [0.   , 0.5  , 0.125, 0.375]])"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DA_STB(MyData, 24, 0, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e681d59-b360-4ab3-b3a0-580dd706ad5e",
   "metadata": {},
   "source": [
    "## Appendix: minimal working code pulp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c0b2b5-5798-479e-93df-a8f0f047d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a simple MILP formulation in Gurobi \n",
    "\n",
    "from pulp import LpProblem, LpVariable, LpMaximize, GUROBI\n",
    "\n",
    "# Define a simple problem\n",
    "prob = LpProblem(\"SimpleProblem\", LpMaximize)\n",
    "\n",
    "# Define variables\n",
    "x = LpVariable(\"x\", lowBound=0)  # x >= 0\n",
    "y = LpVariable(\"y\", lowBound=0)  # y >= 0\n",
    "\n",
    "# Objective Function\n",
    "prob += 3 * x + 2 * y, \"Objective\"\n",
    "\n",
    "# Constraints\n",
    "prob += 2 * x + y <= 20, \"Constraint 1\"\n",
    "prob += 4 * x + 3 * y <= 50, \"Constraint 2\"\n",
    "\n",
    "# Solve using Gurobi API\n",
    "prob.solve(GUROBI())\n",
    "\n",
    "# Print the results\n",
    "print(f\"Status: {prob.status}\")\n",
    "print(f\"x = {x.varValue}\")\n",
    "print(f\"y = {y.varValue}\")\n",
    "prob.writeLP(\"Test.lp\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
