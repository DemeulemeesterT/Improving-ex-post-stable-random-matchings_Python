{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6c60445-8209-43a0-98ad-41b236ec1a61",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1791793-5d3a-42a3-b836-f6d123a7ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Classes import Data, Assignment\n",
    "    # Later, we can move the Class definitions into a separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64e396b6-002b-40bf-bec9-222cf5e75f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pulp in c:\\users\\tdemeule\\appdata\\local\\anaconda3\\lib\\site-packages (2.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: gurobipy in c:\\users\\tdemeule\\appdata\\local\\anaconda3\\lib\\site-packages (12.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyscipopt in c:\\users\\tdemeule\\appdata\\local\\anaconda3\\lib\\site-packages (5.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pulp\n",
    "\n",
    "# Install Gurobi\n",
    "%pip install gurobipy \n",
    "    # Obtain academic license from: https://www.gurobi.com/downloads/end-user-license-agreement-academic/\n",
    "\n",
    "# Install SCIP\n",
    "%pip install pyscipopt\n",
    "\n",
    "# Other useful packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy # To make deep copies\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from numpy.random import default_rng\n",
    "from scipy.stats import norm\n",
    "import time\n",
    "from tqdm import tqdm # To show progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf67a65-30ee-4695-ac1f-31783c45f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GUROBI', 'GUROBI_CMD', 'PULP_CBC_CMD', 'SCIP_CMD', 'FSCIP_CMD', 'SCIP_PY']\n"
     ]
    }
   ],
   "source": [
    "# Check with solvers available on computer\n",
    "import pulp as pl\n",
    "from pulp import *\n",
    "solver_list = pl.listSolvers(onlyAvailable=True)\n",
    "print(solver_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5377d60-7775-4aab-bc4b-55f2abed7ffb",
   "metadata": {},
   "source": [
    "## Define classes\n",
    "Define the following classes:\n",
    "* 'Data': contains\n",
    "    * Number of students\n",
    "    * Number of schools\n",
    "    * Preferences students\n",
    "    * Preferences schools\n",
    "    * Capacities schools\n",
    "    * Names of students\n",
    "    * Names of schools\n",
    "    * File name\n",
    "* 'Assignment': the selection probabilities of the students to the schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2326dc72-5b8e-48fd-9b08-71591f6cf78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    # Define the initialization of an object from this class\n",
    "    def __init__(self, n_stud: int, n_schools: int, pref: list, prior: list, cap:list, ID_stud:list, ID_school:list, file_name:str):\n",
    "        self.n_stud = n_stud\n",
    "        self.n_schools = n_schools\n",
    "        self.pref = copy.deepcopy(pref)\n",
    "        self.prior = copy.deepcopy(prior)\n",
    "        self.cap = copy.deepcopy(cap)\n",
    "        self.ID_stud = copy.deepcopy(ID_stud)\n",
    "        self.ID_school = copy.deepcopy(ID_school)\n",
    "        self.file_name = file_name   \n",
    "\n",
    "        # Create alternative copies of pref and prior in which the elements are no longer strings, \n",
    "        # but the indices of the corresponding elements in the ID vectors\n",
    "        self.pref_index = [[self.ID_school.index(school) for school in student_pref] for student_pref in self.pref]\n",
    "\n",
    "        # Now create two matrices containing the position of the schools in the preferences, and of the students in the priorities\n",
    "        # Initialize the rank matrix with NaN\n",
    "        self.rank_pref = np.full((self.n_stud, self.n_schools), np.nan)\n",
    "\n",
    "        self.prior_index = []\n",
    "        for school_prior in self.prior:\n",
    "            transformed_school_prior = []\n",
    "            for student_group in school_prior:\n",
    "                if isinstance(student_group, tuple):\n",
    "                    transformed_school_prior.append(tuple(ID_stud.index(student) for student in student_group))\n",
    "                else:\n",
    "                    transformed_school_prior.append(ID_stud.index(student_group))\n",
    "            self.prior_index.append(transformed_school_prior)\n",
    "\n",
    "        \n",
    "        # Populate the rank matrix\n",
    "        for i, student_pref in enumerate(self.pref):\n",
    "            for rank_position, school_id in enumerate(student_pref):\n",
    "                if school_id in self.ID_school:\n",
    "                    school_index = self.ID_school.index(school_id)\n",
    "                    self.rank_pref[i][school_index] = rank_position\n",
    "\n",
    "        # Initialize the rank_prior matrix with NaN\n",
    "        self.rank_prior = np.full((self.n_schools, self.n_stud), np.nan)\n",
    "        \n",
    "        # Populate the rank_prior matrix\n",
    "        for j, school_prior in enumerate(self.prior):\n",
    "            for rank_position, student_id in enumerate(school_prior):\n",
    "                # Handle tuple (grouped students) by expanding\n",
    "                if isinstance(student_id, tuple):\n",
    "                    for grouped_student in student_id:\n",
    "                        if grouped_student in self.ID_stud:\n",
    "                            student_index = self.ID_stud.index(grouped_student)\n",
    "                            self.rank_prior[j][student_index] = rank_position + 1  # Positions are 1-based\n",
    "                elif student_id in self.ID_stud:\n",
    "                    student_index = self.ID_stud.index(student_id)\n",
    "                    self.rank_prior[j][student_index] = rank_position + 1  # Positions are 1-based\n",
    "    \n",
    "    # Choose what is being shown for the command 'print(MyData)', where 'MyData' is an instance of the class 'Data'\n",
    "    def __str__(self):\n",
    "        s =\"The data instance has the following properties: \\n\"\n",
    "        s += f\"\\n\\t{self.n_stud} students.\\n\\t{self.n_schools} schools. \\n\\n \\tPREFERENCES:\\n\"\n",
    "        for i in range(0,self.n_stud):\n",
    "            s+= f\"\\t{self.ID_stud[i]}\\t\"\n",
    "            for j in range(0, len(self.pref[i])):\n",
    "                s+=f\"{self.pref[i][j]} \"\n",
    "            s +=\"\\n\"\n",
    "\n",
    "        s += f\"\\n\\n \\tCAPACITIES & PRIORITIES:\\n\"\n",
    "        for i in range(0,self.n_schools):\n",
    "            s+= f\"\\t{self.ID_school[i]}\\t\"\n",
    "            s+= f\"{self.cap[i]}\\t\"\n",
    "            for j in range(0, len(self.prior[i])):\n",
    "                if len(self.prior[i][j]) >= 2:\n",
    "                    s+=f\"{{\"\n",
    "                    for k in range(0, len(self.prior[i][j])):\n",
    "                        s+=f\"{self.prior[i][j][k]}\"\n",
    "                        if k < len(self.prior[i][j]) - 1:\n",
    "                            s+= f\" \"\n",
    "                    s+=f\"}} \"\n",
    "                else:\n",
    "                    s+=f\"{self.prior[i][j]} \"\n",
    "            s +=\"\\n\"\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f9cd87d-cfc4-4f9e-ad89-eb06e68cc1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assignment:\n",
    "    # This class will contain an assignment\n",
    "    def __init__(self, MyData: Data, p: np.ndarray, label = None):\n",
    "        # self.file_name = MyData.file_name[:-4] \n",
    "            # Use this when importing .csv files, for example\n",
    "        self.file_name = MyData.file_name\n",
    "        self.MyData = copy.deepcopy(MyData)\n",
    "        self.assignment = copy.deepcopy(p)\n",
    "        self.label = label\n",
    "        if label == None:\n",
    "            self.label = \"\"\n",
    "        \n",
    "        names = []\n",
    "        for i in range(0,MyData.n_stud):\n",
    "            names.append(\"Choice {}\".format(i + 1))\n",
    "        \n",
    "        # Same as assignment, but ranked in decreasing order of preference\n",
    "        self.assignment_ranked = np.zeros(shape=(MyData.n_stud, MyData.n_schools), dtype = np.float64)\n",
    "        counter =  0\n",
    "        for i in range(0, MyData.n_stud):\n",
    "            for j in range(0, len(MyData.pref[i])):\n",
    "                \n",
    "                # Convert pref[i][k] (school ID as string) to column index\n",
    "                #col_index = int(MyData.pref[i][j]) - 1\n",
    "                col_index = MyData.ID_school.index(MyData.pref[i][j])\n",
    "                self.assignment_ranked[i][j] = self.assignment[i][col_index]\n",
    "                counter += 1\n",
    "        #self.assignment_ranked = pd.DataFrame(ranked, columns = names)\n",
    "\n",
    "    \n",
    "        # Export assignment\n",
    "        self.export_assignment()\n",
    "    \n",
    "    # Visualize the assignment in different ways\n",
    "    def visualize(self):\n",
    "        # To export the figures, check if the correct folder exists:\n",
    "        if os.path.exists(\"Results\") == False:\n",
    "            # If not, create folder\n",
    "            os.makedirs(\"Results\")\n",
    "        \n",
    "        s = os.path.join(\"Results\", \"Visualisations\")\n",
    "        if os.path.exists(s) == False:\n",
    "            # If not, create folder\n",
    "            os.makedirs(s)\n",
    "        \n",
    "        s = os.path.join(\"Results\", \"Visualisations\",self.file_name)\n",
    "        if os.path.exists(s) == False:\n",
    "            os.makedirs(s)\n",
    "            \n",
    "        \n",
    "        path = \"Results/Visualisations/\"\n",
    "        # The assignment itself\n",
    "        sns.set(rc = {'figure.figsize':(MyData.n_stud,MyData.n_schools/1.5)})\n",
    "        \n",
    "        # Create a custom colormap (to show negative values red)\n",
    "        colors = [\"red\", \"white\", \"blue\"]  # Red for negatives, white for 0, blue for positives\n",
    "        custom_cmap = LinearSegmentedColormap.from_list(\"CustomMap\", colors)\n",
    "        \n",
    "        # Create the heatmap\n",
    "        p = sns.heatmap(self.assignment, cmap = custom_cmap, center=0, annot=True, yticklabels = MyData.ID_stud, xticklabels = MyData.ID_school)\n",
    "        p.set_xlabel(\"Students\", fontsize = 15)\n",
    "        p.set_ylabel(\"Schools\", fontsize = 15)\n",
    "        name = path + self.file_name + \"/\" + self.label + \".pdf\"\n",
    "        p.set_title(self.label, fontsize = 20)\n",
    "        plt.savefig(name, format=\"pdf\", bbox_inches=\"tight\")\n",
    "        \n",
    "        # Assignment, ranked by preference\n",
    "        plt.figure()\n",
    "\n",
    "        # Create a custom colormap (to show negative values red)\n",
    "        colors = [\"red\", \"white\", \"green\"]  # Red for negatives, white for 0, blue for positives\n",
    "        custom_cmap2 = LinearSegmentedColormap.from_list(\"CustomMap\", colors)\n",
    "        \n",
    "        # Create the heatmap\n",
    "        sns.set(rc = {'figure.figsize':(MyData.n_stud,MyData.n_schools/1.5)})\n",
    "        p = sns.heatmap(self.assignment_ranked, cmap = custom_cmap2, center=0, annot=True, yticklabels = MyData.ID_stud, xticklabels = range(1,MyData.n_schools + 1))\n",
    "        p.set_xlabel(\"Preference\", fontsize = 15)\n",
    "        p.set_ylabel(\"Students\", fontsize = 15)\n",
    "        name = path + self.file_name + \"/\" + self.label + \"_Ranked.pdf\"\n",
    "        title = self.file_name + \": ranked by decreasing preference\"\n",
    "        p.set_title(title, fontsize = 20)\n",
    "        plt.savefig(name, format=\"pdf\", bbox_inches=\"tight\")\n",
    "        \n",
    "        plt.figure()\n",
    "    \n",
    "    # Save the assignment to the correct subdirectory\n",
    "    def export_assignment(self):\n",
    "        if os.path.exists(\"Results\") == False:\n",
    "            # If not, create folder\n",
    "            os.makedirs(\"Results\")\n",
    "\n",
    "        s = os.path.join(\"Results\", \"Assignments\")\n",
    "        if os.path.exists(s) == False:\n",
    "            # If not, create folder\n",
    "            os.makedirs(s)\n",
    "\n",
    "        s = os.path.join(\"Results\", \"Assignments\",self.file_name)\n",
    "        if os.path.exists(s) == False:\n",
    "            os.makedirs(s)\n",
    "        \n",
    "        name = \"Results/Assignments/\" + self.file_name + \"/\" + self.label + \"_\" + self.file_name + \".csv\"\n",
    "        np.savetxt(name, self.assignment, delimiter=\",\")\n",
    "        \n",
    "    # Choose what is being shown for the command 'print(Sol)', where 'Sol' is an instance of the class 'Assignment'\n",
    "    def __str__(self):\n",
    "        \n",
    "        return s\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ff12e4b-8541-4f54-a018-32e444307c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model: \n",
    "    \"\"\"\n",
    "    Contains two methods:\n",
    "        __init__: initializes the model, and the solver environment\n",
    "\n",
    "        Solve: solves the model.\n",
    "            The parameters of this method can control which objective function is optimized, and which solver is used\n",
    "    \"\"\"\n",
    "    \n",
    "    # Used this example as a template for Pulp: https://coin-or.github.io/pulp/CaseStudies/a_sudoku_problem.html\n",
    "    \n",
    "    def __init__(self, MyData: Data, p: Assignment, print_out: bool, nr_matchings = -1):\n",
    "        \"\"\"\n",
    "        Initialize an instance of Model.\n",
    "\n",
    "        Args:\n",
    "            MyData (type: Data): instance of class Data.\n",
    "            p (type: Assignment): instance of class Assignment.\n",
    "            print_out (type: bool): boolean that controls which output is printed.\n",
    "            nr_matchings (optional): number of matchings used in the decomposition, optional parameter that defaults to n_students * n_schools + 1\n",
    "\n",
    "        \"\"\"\n",
    "        # 'nr_matchings' refers to number of matchings used to find decomposition\n",
    "        self.MyData = copy.deepcopy(MyData)\n",
    "        self.p = copy.deepcopy(p)\n",
    "        self.nr_matchings = nr_matchings\n",
    "        if nr_matchings == -1:\n",
    "            self.nr_matchings = self.MyData.n_stud * self.MyData.n_schools + 1\n",
    "\n",
    "        # Create the pulp model\n",
    "        self.model = LpProblem(\"Improving_ex_post_stable_matchings\", LpMinimize)\n",
    "\n",
    "        # Create variables to store the solution in\n",
    "        self.Xdecomp = [] # Matchings in the found decomposition\n",
    "        self.Xdecomp_coeff = [] # Weights of these matchings\n",
    "        zero = np.zeros(shape=(self.MyData.n_stud, self.MyData.n_schools))\n",
    "        self.Xassignment = Assignment(MyData, zero) # Contains the final assignment found by the model\n",
    "\n",
    "        #### DECISION VARIABLES ####\n",
    "        self.STUD = range(0,self.MyData.n_stud)\n",
    "        self.SCHOOLS = range(0, self.MyData.n_schools)\n",
    "        self.N_MATCH = range(0, self.nr_matchings)\n",
    "\n",
    "        # Tuple with all student-school pairs that are preferred to outside option\n",
    "        # This tuple contains the INDICES of the students and the pairs, and not their original names\n",
    "        self.PAIRS = []\n",
    "        for i in range(0, MyData.n_stud):\n",
    "            for j in range(0,len(MyData.pref[i])):\n",
    "                # Convert pref[i][k] (school ID as string) to column index\n",
    "                col_index = MyData.ID_school.index(MyData.pref[i][j])\n",
    "                self.PAIRS.append((i,col_index))   \n",
    "        \n",
    "        # M[k][i][j] = 1 if student i is assigned to school j in matching k, and 0 otherwise\n",
    "        self.M = LpVariable.dicts(\"M\", [(k, i, j) for k in self.N_MATCH for i, j in self.PAIRS], cat=\"Binary\")\n",
    "\n",
    "        # Auxiliary variables to avoid non-linearity\n",
    "        self.z = LpVariable.dicts(\"z\", [(k, i, j) for k in self.N_MATCH for (i, j) in self.PAIRS], 0, 1)\n",
    "\n",
    "        # Rename M and z\n",
    "        for k, i, j in self.M:\n",
    "            student_name = self.MyData.ID_stud[i]\n",
    "            school_name = self.MyData.ID_school[j]\n",
    "            self.M[k, i, j].name = f\"M_{k}_{student_name}_{school_name}\"\n",
    "            self.z[k, i, j].name = f\"z_{k}_{student_name}_{school_name}\"\n",
    "\n",
    "        # Q[i][j] is the new probability with which student i is assigned to school j, lies between 0 and 1\n",
    "        self.Q = LpVariable.dicts(\"q\", self.PAIRS, 0, 1) \n",
    "    \n",
    "        # w[k] is the weight of matching k in the decomposition\n",
    "        self.w = LpVariable.dicts(\"w\", self.N_MATCH, 0, 1)\n",
    "\n",
    "        #### OBJECTIVE FUNCTION ####\n",
    "            # Done separately in other functions (see function Solve)\n",
    "        \n",
    "            \n",
    "        #### CONSTRAINTS ####\n",
    "        # Other constraints defined for specific models in functions below (see function Solve)\n",
    "\n",
    "        if print_out:\n",
    "            print(\"Stability constraints...\")\n",
    "        # Stability\n",
    "        for k in self.N_MATCH:\n",
    "            for i in self.STUD:\n",
    "                for j in range(len(self.MyData.pref_index[i])):\n",
    "                    current_school = self.MyData.pref_index[i][j]\n",
    "                    lin = LpAffineExpression()\n",
    "\n",
    "                    lin += self.MyData.cap[current_school] * self.M[k, i, current_school]\n",
    "\n",
    "                    # Add all schools that are at least as preferred as the j-ranked school by student i\n",
    "                    for l in range(j):\n",
    "                        lin += self.MyData.cap[current_school] * self.M[k,i,self.MyData.pref_index[i][l]]\n",
    "\n",
    "\n",
    "                    # Add terms based on priorities\n",
    "                    prior_current = self.MyData.rank_prior[current_school][i]\n",
    "                    for s in self.STUD:\n",
    "                        if s != i:\n",
    "                            # If current_school ranks student s higher than student i\n",
    "                            if self.MyData.rank_prior[current_school][s] <= self.MyData.rank_prior[current_school][i]:\n",
    "                                if (s, current_school) in self.PAIRS:\n",
    "                                    lin += self.M[k,s,current_school]\n",
    "\n",
    "                    # Add to model:\n",
    "                    name = \"STAB_\" + str(k) + \"_\" + str(self.MyData.ID_stud[i]) + \"_\" + str(self.MyData.ID_school[current_school]) \n",
    "                    self.model += (lin >= self.MyData.cap[current_school], name) \n",
    "\n",
    "        \n",
    "        # Each student at most assigned to one school\n",
    "        if print_out:\n",
    "            print(\"Capacity constraints...\")\n",
    "        for l in self.N_MATCH:\n",
    "            for i in self.STUD:\n",
    "                self.model += lpSum([self.M[l,i,j] for j in self.SCHOOLS if (i,j) in self.PAIRS]) <= 1, f\"LESS_ONE_{l,i}\"\n",
    "\n",
    "        # Capacities schools respected\n",
    "        for l in self.N_MATCH:\n",
    "            for j in self.SCHOOLS:\n",
    "                self.model += lpSum([self.M[l,i,j] for i in self.STUD if (i,j) in self.PAIRS]) <= self.MyData.cap[j], f\"LESS_CAP_{l,j}\"\n",
    "                                    \n",
    "\n",
    "    def Solve(self, obj: str, solver: str, print_out: bool):\n",
    "        \"\"\"\n",
    "        Solves the formulation.\n",
    "        Returns an instance from the Assignment class.\n",
    "\n",
    "        Args:\n",
    "            obj (str): controls the objective function\n",
    "                \"IMPR_RANK\": minimizes expected rank while maintaining ex-post stability\n",
    "                \"STABLE\": maximizes fraction of stable matchings in decomposition\n",
    "            solver (str): controls which solver is used. See options through following commands:\n",
    "                solver_list = pl.listSolvers(onlyAvailable=True)\n",
    "                print(solver_list)\n",
    "            print_out (bool): boolean that controls which output is printed.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Check that strings-arguments are valid\n",
    "\n",
    "        # Valid values for 'solver'\n",
    "        solver_list = pl.listSolvers(onlyAvailable=True)\n",
    "        if solver not in solver_list:\n",
    "           raise ValueError(f\"Invalid value: '{solver}'. Allowed values are: {solver_list}\")\n",
    "\n",
    "        # Valid values for 'obj'\n",
    "        obj_list = [\"IMPR_RANK\", \"STABLE\"]\n",
    "        if obj not in obj_list:\n",
    "           raise ValueError(f\"Invalid value: '{obj}'. Allowed values are: {obj_list}\")\n",
    "\n",
    "        #### FORMULATION ####\n",
    "        \n",
    "        # Set the objective function\n",
    "        if obj == \"IMPR_RANK\":\n",
    "            self.Improve_rank(print_out)\n",
    "        \n",
    "        elif obj == \"STABLE\":\n",
    "            self.Max_Stable_Fraction(print_out)\n",
    "\n",
    "        self.model.writeLP(\"Test.lp\")\n",
    "\n",
    "        \n",
    "        #### SOLVE ####\n",
    "            \n",
    "        # String can't be used as the argument in solve method, so convert it like this:\n",
    "        solver_function = globals()[solver]  # Retrieves the GUROBI function or class\n",
    "        \n",
    "        # Solve the formulation\n",
    "        self.model.solve(solver_function())\n",
    "        #self.model.solve(GUROBI_CMD(keepFiles=True, msg=True, options=[(\"IISFind\", 1)]))\n",
    "        \n",
    "        #### STORE SOLUTION ####\n",
    "        # Make sure assignment is empty in Xassignment\n",
    "        self.Xassignment.assignment = np.zeros(shape=(self.MyData.n_stud, self.MyData.n_schools))\n",
    "\n",
    "        for (i,j) in self.PAIRS:\n",
    "            self.Xassignment.assignment[i,j] = self.Q[i,j].varValue\n",
    "\n",
    "        # Store decomposition\n",
    "        self.Xdecomp = [] # Matchings in the found decomposition\n",
    "        self.Xdecomp_coeff = [] # Weights of these matchings\n",
    "\n",
    "        for l in self.N_MATCH:\n",
    "            self.Xdecomp.append(np.zeros(shape=(self.MyData.n_stud, self.MyData.n_schools)))\n",
    "            self.Xdecomp_coeff.append(self.w[l].varValue)\n",
    "            for (i,j) in self.PAIRS:\n",
    "                self.Xdecomp[-1][i,j] = self.M[l,i,j].varValue\n",
    "                \n",
    "        return self.Xassignment\n",
    "\n",
    "\n",
    "    def Improve_rank(self, print_out: str):\n",
    "        \"\"\"\n",
    "        Creates and solves formulation to minimize the expected rank while ensuring the found random matching is ex-post stable.\n",
    "        \"\"\"\n",
    "        \n",
    "        if print_out == True:\n",
    "            # Compute average rank of current assignment\n",
    "\n",
    "            sum = 0\n",
    "            for (i,j) in self.PAIRS:\n",
    "                sum += self.p.assignment[i,j] * (self.MyData.rank_pref[i,j] + 1) # + 1 because the indexing starts from zero\n",
    "            # Average\n",
    "            sum = sum/self.MyData.n_stud\n",
    "            print(f\"\\nAverage rank before optimization: {sum}.\\n\\n\")\n",
    "        \n",
    "        # Objective function\n",
    "        lin = LpAffineExpression()\n",
    "        for (i,j) in self.PAIRS:\n",
    "            lin += (self.Q[i,j] * (self.MyData.rank_pref[i,j] + 1)) / self.MyData.n_stud # + 1 because the indexing starts from zero\n",
    "        self.model += lin\n",
    "\n",
    "        # Define q based on matchings in decomposition\n",
    "            # Where z is an auxiliary variable to avoid non-linearities\n",
    "        if print_out:\n",
    "            print(\"Constraints with auxiliary z...\")\n",
    "        for l in self.N_MATCH:\n",
    "            for (i,j) in self.PAIRS:\n",
    "                self.model += self.z[l, i, j] - self.w[l] <= 0,f\"z_w{l,i,j}\" \n",
    "\n",
    "        for l in self.N_MATCH:\n",
    "            for (i,j) in self.PAIRS:\n",
    "                self.model += self.z[l, i, j] - self.M[l, i, j] <= 0,f\"z_M_{l, i, j}\"\n",
    "\n",
    "        for l in self.N_MATCH:\n",
    "            for (i,j) in self.PAIRS:\n",
    "                self.model += self.z[l, i, j] + (1 - self.M[l, i, j]) - self.w[l]  >= 0,f\"z_w_M_{l, i, j}\"\n",
    "                # Maybe these constraints are redundant because of the objective function\n",
    "\n",
    "        for (i,j) in self.PAIRS:\n",
    "            self.model += lpSum([self.z[l, i, j] for l in self.N_MATCH]) == self.Q[i,j], f\"z_Q_{i, j}\"\n",
    "\n",
    "        # Ensure weights sum up to one\n",
    "        self.model += lpSum([self.w[l] for l in self.N_MATCH]) == 1, f\"SUM_TO_ONE\"\n",
    "\n",
    "        # First-order stochastic stability\n",
    "        if print_out:\n",
    "            print(\"FOSD constraints...\")\n",
    "        for i in self.STUD:\n",
    "            for j in range(len(self.MyData.pref[i])):\n",
    "                lin = LpAffineExpression()\n",
    "                for k in range(j+1):\n",
    "                    pref_school = self.MyData.pref_index[i][k]\n",
    "                    lin += self.Q[i,pref_school]\n",
    "                    lin -= self.p.assignment[i,pref_school]\n",
    "                name = \"FOSD_\" +  str(self.MyData.ID_stud[i]) + \"_\" + str(j)\n",
    "                self.model += (lin >= 0, name)\n",
    "\n",
    "\n",
    "    def Max_Stable_Fraction(self, print_out: str):\n",
    "        # Objective function\n",
    "        obj = LpAffineExpression()\n",
    "        for l in self.N_MATCH:\n",
    "            obj += self.w[l] \n",
    "        self.model += obj\n",
    "        self.model.sense = LpMaximize\n",
    "\n",
    "        # Constraints to ensure that decomposition is at least equal to p (element-wise)\n",
    "            # Where z is an auxiliary variable to avoid non-linearities\n",
    "        if print_out:\n",
    "            print(\"Constraints with auxiliary z...\")\n",
    "        for l in self.N_MATCH:\n",
    "            for (i,j) in self.PAIRS:\n",
    "                self.model += self.z[l, i, j] - self.w[l] <= 0,f\"z_w{l,i,j}\" \n",
    "\n",
    "        for l in self.N_MATCH:\n",
    "            for (i,j) in self.PAIRS:\n",
    "                self.model += self.z[l, i, j] - self.M[l, i, j] <= 0,f\"z_M_{l, i, j}\"\n",
    "\n",
    "        for l in self.N_MATCH:\n",
    "            for (i,j) in self.PAIRS:\n",
    "                self.model += self.z[l, i, j] + (1 - self.M[l, i, j]) - self.w[l]  >= 0,f\"z_w_M_{l, i, j}\"\n",
    "                # Maybe these constraints are redundant because of the objective function\n",
    "\n",
    "        for (i,j) in self.PAIRS:\n",
    "            self.model += lpSum([self.z[l, i, j] for l in self.N_MATCH]) == self.Q[i,j], f\"z_Q_{i, j}\"\n",
    "\n",
    "        for (i,j) in self.PAIRS:\n",
    "            self.model += lpSum([self.z[l, i, j] for l in self.N_MATCH]) <= self.p.assignment[i,j], f\"z_p_{i, j}\"\n",
    "        \n",
    "\n",
    "    def print_solution(self):\n",
    "        s = \"The obtained random matching is:\\n\"\n",
    "        s+=f\"\\t\\t\"\n",
    "        for j in self.SCHOOLS:\n",
    "            s+=f\"{self.MyData.ID_school[j]}\\t\"\n",
    "        s+=\"\\n\"\n",
    "        for i in self.STUD:\n",
    "            s+= f\"\\t{self.MyData.ID_stud[i]}\\t\"\n",
    "            for j in self.SCHOOLS:\n",
    "                s+=f\"{self.Xassignment.assignment[i,j]}\\t\"\n",
    "            s+=f\"\\n\"\n",
    "        s+=f\"\\n\"\n",
    "\n",
    "        s+= \"The matchings with positive weights are:\\n\"\n",
    "\n",
    "        for l in self.N_MATCH:\n",
    "            if self.Xdecomp_coeff[l] > 0:\n",
    "                s+=f\"\\t w[{l}] = {self.Xdecomp_coeff[l]}\\n\"\n",
    "                for i in self.STUD:\n",
    "                    s+=f\"\\t\\t\"\n",
    "                    for j in self.SCHOOLS:\n",
    "                        if self.Xdecomp[l][i,j] == 1:\n",
    "                            s+=f\"1\\t\"\n",
    "                        else:\n",
    "                            s+= f\"0\\t\"\n",
    "                    s+=f\"\\n\"\n",
    "                s+=f\"\\n\"\n",
    "        print(s)\n",
    "\n",
    "        \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6de866b-7763-4047-a82a-c73dbd6d94bd",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fb65c44-c427-4dcb-b5cc-0c92ec926ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenParam:\n",
    "    # Parameters to used for data generation, see https://github.com/DemeulemeesterT/GOSMI\n",
    "    \n",
    "    def __init__(self, capacity_ratio=1.2, corr_cap_pop=0.21, mean_pref=2.42, sigma_pref=1.05, \n",
    "                 CV_cap=0.8, CV_pop=0.6, delta_1=0.14, delta_2=0.009, pop_percentage=0.10):\n",
    "        self.capacity_ratio = capacity_ratio\n",
    "        self.corr_cap_pop = corr_cap_pop\n",
    "        self.mean_pref = mean_pref\n",
    "        self.sigma_pref = sigma_pref\n",
    "        self.CV_cap = CV_cap\n",
    "        self.CV_pop = CV_pop\n",
    "        self.delta_1 = delta_1\n",
    "        self.delta_2 = delta_2\n",
    "        self.pop_percentage = pop_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56801ed6-ee53-4c64-9a39-0864afb98226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_students: int, n_schools: int, parameters: DataGenParam, name: str, print_data=False, seed=123456789):\n",
    "    \"\"\"\n",
    "    Generate data. The preferences and capacities are based on: https://github.com/DemeulemeesterT/GOSMI\n",
    "\n",
    "    Parameters:\n",
    "    - n_students: Number of students.\n",
    "    - n_schools: Number of schools.\n",
    "    - parameters: An instance of DataGenParam with generation parameters.\n",
    "    - print_data: Whether to print the generated data.\n",
    "    - seed: Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - An object of the class Data\n",
    "    \"\"\"\n",
    "    if seed != 123456789:\n",
    "        # Use seed in argument\n",
    "        rng = default_rng(seed)\n",
    "    else:\n",
    "        # Generate random seed \n",
    "        # Create a seed based on the current time\n",
    "        seed = int(time.time() * 1000) % (2**32)  # Modulo 2^32 to ensure it's a valid seed\n",
    "\n",
    "    # Initialize arrays\n",
    "    students = list(range(n_students))\n",
    "    schools = list(range(n_schools))\n",
    "\n",
    "    # Generate capacities and popularity\n",
    "    capacity_total = int(round(parameters.capacity_ratio * n_students))\n",
    "    capacity_aid = rng.normal(0, 1, n_schools)\n",
    "    popularity_aid = rng.normal(0, 1, n_schools)\n",
    "    \n",
    "    # Cholesky decomposition for correlated random variables\n",
    "    covar = np.array([\n",
    "        [1, parameters.corr_cap_pop],\n",
    "        [parameters.corr_cap_pop, 1]\n",
    "    ])\n",
    "    G = np.linalg.cholesky(covar).T\n",
    "    correlated = G @ np.vstack((capacity_aid, popularity_aid))\n",
    "    capacity_aid, popularity_aid = correlated[0], correlated[1]\n",
    "\n",
    "    # Rescale capacities\n",
    "    mean_capacity_aid = np.mean(capacity_aid)\n",
    "    capacities = np.round((capacity_total / n_schools) * \n",
    "                          (1 + parameters.CV_cap * (capacity_aid - mean_capacity_aid)))\n",
    "    capacities = np.clip(capacities, 1, None).astype(int)  # Ensure no capacity < 1\n",
    "    scale_factor = capacity_total / np.sum(capacities)\n",
    "    capacities = np.round(capacities * scale_factor).astype(int)\n",
    "\n",
    "    # Generate preference lengths\n",
    "    pref_lengths = rng.normal(parameters.mean_pref, parameters.sigma_pref, n_students)\n",
    "    pref_lengths = np.clip(pref_lengths, 1, n_schools).astype(int)\n",
    "\n",
    "    # Determine popularity thresholds\n",
    "    mean_pop_ratio = np.sum(pref_lengths) / np.sum(capacities)\n",
    "    mean_popularity_aid = np.mean(popularity_aid)\n",
    "    popularity_aid = mean_pop_ratio * (1 + parameters.CV_pop * (popularity_aid - mean_popularity_aid))\n",
    "    popularity_aid = np.clip(popularity_aid, 0.2, None)  # Ensure no popularity < 0.2\n",
    "    requests = capacities * popularity_aid\n",
    "    popularity_aid *= np.sum(pref_lengths) / np.sum(requests)\n",
    "\n",
    "    # Define popular schools\n",
    "    sorted_indices = np.argsort(-popularity_aid)\n",
    "    popularity_threshold = popularity_aid[sorted_indices[int(parameters.pop_percentage * n_schools)]]\n",
    "    popular = popularity_aid > popularity_threshold\n",
    "\n",
    "    # Generate preferences for each student\n",
    "    preferences = []\n",
    "    for i in range(n_students):\n",
    "        student_pref = []\n",
    "        available_schools = list(range(n_schools))\n",
    "        for _ in range(pref_lengths[i]):\n",
    "            weights = popularity_aid[available_schools]\n",
    "            weights /= np.sum(weights)\n",
    "            choice = rng.choice(available_schools, p=weights)\n",
    "            student_pref.append(choice) \n",
    "            available_schools.remove(choice)\n",
    "        preferences.append(student_pref)\n",
    "\n",
    "    # Generate random school priorities:\n",
    "    # For now, just simply\n",
    "        # Randomly order students for each school\n",
    "        # Divide into three indifference groups for each school\n",
    "\n",
    "    priorities = []\n",
    "    for j in range(n_schools):\n",
    "        permutation = np.random.permutation(students)\n",
    "\n",
    "        # Split the list into three roughly equal groups\n",
    "        group_size = len(permutation) // 3\n",
    "        group1 = permutation[:group_size]\n",
    "        group2 = permutation[group_size:2 * group_size]\n",
    "        group3 = permutation[2 * group_size:]\n",
    "\n",
    "        priorities.append([tuple(group1), tuple(group2), tuple(group3)])\n",
    "    \n",
    "    # Optionally print data\n",
    "    if print_data:\n",
    "        print(f\"Generated data with {n_students} students and {n_schools} schools.\")\n",
    "        print(f\"Preferences: {preferences}\")\n",
    "        print(f\"Priorities: {priorities}\")\n",
    "        print(f\"Capacities: {list(capacities)}\")\n",
    "        # print(f\"Popularity Ratios: {list(popularity_aid)}\")\n",
    "        print(f\"Students: {students}\")\n",
    "        print(f\"Schools: {schools}\")\n",
    "    \n",
    "    MyData = Data(n_students, n_schools, preferences, priorities, capacities, students, schools, name)\n",
    "    \n",
    "    # Return results\n",
    "    return MyData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487fab23-882b-4739-8e03-3f2fa56bd10d",
   "metadata": {},
   "source": [
    "## Gale-Shapley algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce62dd6c-6546-4fdb-80bf-845a70b8f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gale_shapley(MyData: Data):\n",
    "    \"\"\"\n",
    "    Gale-Shapley algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    - An instance from the Data class\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array containing the assignment\n",
    "    \"\"\"\n",
    "    n_stud = len(MyData.pref)\n",
    "    n_schools = len(MyData.prior)\n",
    "    pref = copy.deepcopy(MyData.pref) # We will gradually delete preferences from this \n",
    "\n",
    "    # Initialize data structures\n",
    "    free_stud = list(range(n_stud))  # List of free students by index\n",
    "    # Initialize temp_assigned with empty lists for each school\n",
    "    temp_assigned = {school_index: [] for school_index in range(len(MyData.cap))} \n",
    "\n",
    "    while free_stud:\n",
    "        # First we go through all students in 'free_stud' and remove them from the list\n",
    "        while free_stud:\n",
    "            i = free_stud[0]  # Get the first student\n",
    "            free_stud.pop(0)  # Remove it\n",
    "            # Assign free students to their most preferred school among remaining choices...\n",
    "            # ... if preference list not empty yet\n",
    "            if len(pref[i])>0:\n",
    "                # Find index of that school\n",
    "                index = MyData.ID_school.index(pref[i][0])\n",
    "                temp_assigned[index].append(i) \n",
    "    \n",
    "                # Remove that school from student i's preferences\n",
    "                pref[i].pop(0)\n",
    "\n",
    "        # Now each school j only keeps cap[j] most preferred students, and the others will be added to free_stud again\n",
    "        for j in range(n_schools):\n",
    "            if len(temp_assigned[j]) > MyData.cap[j]:\n",
    "                # Dictionary containing priorities of the students who are temporarily assigned to school j\n",
    "                prior_values = {stud_index: [] for stud_index in temp_assigned[j]}  \n",
    "                for i in range(len(temp_assigned[j])):\n",
    "                    # Find the position of student temp_assigned[j][i] in the priority list of school j\n",
    "                    prior_values[temp_assigned[j][i]] = MyData.prior[j].index(MyData.ID_stud[temp_assigned[j][i]])\n",
    "\n",
    "                # Sort the dictionary prior_values items by value\n",
    "                sorted_prior_values = sorted(prior_values.items(), key=lambda item: item[1])\n",
    "\n",
    "                # Remove the least preferred students who exceed capacity, and add them to free_students\n",
    "                while len(temp_assigned[j]) > MyData.cap[j]:\n",
    "                    # Add to free_stud\n",
    "                    free_stud.append(sorted_prior_values[MyData.cap[j]][0])\n",
    "\n",
    "                    # Remove from temp_assigned\n",
    "                    temp_assigned[j].remove(sorted_prior_values[MyData.cap[j]][0])\n",
    "\n",
    "                    # Remove from sorted_prior_values\n",
    "                    sorted_prior_values.pop(MyData.cap[j])\n",
    "    \n",
    "    # Finally, transform the assignment in a numpy array where M[i][j] = 1 if student i is assigned to school j\n",
    "    M = np.zeros(shape=(n_stud, n_schools))\n",
    "    for j in range(n_schools):\n",
    "        for k in range(len(temp_assigned[j])):\n",
    "            M[temp_assigned[j][k]][j] = 1\n",
    "    \n",
    "    return M\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6888de94-f4fe-475e-855a-69b294772cfa",
   "metadata": {},
   "source": [
    "## Sample Deferred Acceptance with tie-breaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bac68da-5dc3-4649-a756-3d716efa51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DA_STB(MyData: Data, n_iter: int, seed = 123456789, print_out = False):\n",
    "    \"\"\"\n",
    "    Deferred Acceptance with single tie-breaking\n",
    "\n",
    "    Parameters:\n",
    "    - MyData: An instance from the Data class\n",
    "    - n_iter: number of tie-breakings sampled\n",
    "    - print_out: boolean to control output on the screen\n",
    "\n",
    "    Returns:\n",
    "    - An instance of the Assignment class\n",
    "    \"\"\"\n",
    "\n",
    "    if seed != 123456789:\n",
    "        # Use seed in argument\n",
    "        rng = default_rng(seed)\n",
    "    else:\n",
    "        # Generate random seed \n",
    "        # Create a seed based on the current time\n",
    "        seed = int(time.time() * 1000) % (2**32)  # Modulo 2^32 to ensure it's a valid seed\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # First, check how many tie-breaking rules would be needed in total\n",
    "    # Look at total number of students who are included in ties\n",
    "    students_in_ties = set()\n",
    "    for j in range(MyData.n_schools):\n",
    "        for k in range(len(MyData.prior[j])):\n",
    "            if len(MyData.prior[j][k]) >= 2: # When more than a single student in this element\n",
    "                for l in range(len(MyData.prior[j][k])):\n",
    "                    # students_in_ties.add(MyData.ID_stud.index(MyData.prior[j][k][l])) # We add the index of this student, not its name\n",
    "                    students_in_ties.add(MyData.prior[j][k][l])\n",
    "\n",
    "    students_in_ties = list(students_in_ties) # Convert the set to a list, allows us to access k-th element\n",
    "    \n",
    "    # The total number of needed tie-breaking rules is m!, where m = |student_in_ties|\n",
    "    n_STB = math.factorial(len(students_in_ties))\n",
    "\n",
    "    # We only need to perturb the students who appear in ties:\n",
    "    \n",
    "    if n_STB < n_iter:\n",
    "        n_iter = n_STB\n",
    "        # Enumerate all relevant permutations\n",
    "        permut = list(itertools.permutations(students_in_ties))\n",
    "    else:\n",
    "        permut = set() # We first create a set, to ensure that all found permutations are unique. Later, convert to list\n",
    "        # Sample n_iter out of all n_STB relevant permutations\n",
    "        while len(permut) < n_iter:\n",
    "            np.random.shuffle(students_in_ties)  # Shuffle in place\n",
    "            permut.add(tuple(students_in_ties))\n",
    "        permut = list(permut)\n",
    "    \n",
    "    if print_out:\n",
    "        print(f\"Students in ties: {len(students_in_ties)}\")\n",
    "        print(f\"Tie-breaking rules needed: {n_STB}\")\n",
    "        print(f\"Tie-breaking rules sampled: {n_iter}\")\n",
    "        # print(f\"permut: {permut}\")\n",
    "\n",
    "    # For each of the permutations, break ties in the preferences and run Gale-Shapley algorithm on them\n",
    "    M_sum = np.zeros(shape=(MyData.n_stud, MyData.n_schools)) # Will contain the final random_assignment\n",
    "\n",
    "    for p in tqdm(permut):\n",
    "        prior_new = [] \n",
    "        for j in range(len(MyData.prior)):\n",
    "            # Just add priorities if no ties:\n",
    "            if len(MyData.prior[j]) == MyData.n_stud:\n",
    "                prior_new.append(MyData.prior[j])\n",
    "            else:\n",
    "                prior_array = []\n",
    "                for k in range(len(MyData.prior[j])):\n",
    "                    if len(MyData.prior[j][k]) == 1:\n",
    "                        prior_array.append(MyData.prior[j][k])\n",
    "                    else: # set of students who have same priorities\n",
    "                        # Reorder the students based on the permuation\n",
    "                        reordered_prior = list(sorted(MyData.prior[j][k], key=lambda x: p.index(x)))\n",
    "\n",
    "                        # Add to prior_array\n",
    "                        for l in range(len(MyData.prior[j][k])):\n",
    "                            prior_array.append(reordered_prior[l])\n",
    "                prior_new.append(prior_array)\n",
    "                \n",
    "        # Compute DA matching for the new priorities after tie-breaking\n",
    "        Data_new_prior = Data(MyData.n_stud, MyData.n_schools, MyData.pref, prior_new, MyData.cap, MyData.ID_stud, MyData.ID_school, MyData.file_name)\n",
    "        M_sum = M_sum + gale_shapley(Data_new_prior)            \n",
    "        \n",
    "    M_sum = M_sum / n_iter\n",
    "\n",
    "    # Create an instance of the Assignment class\n",
    "    label = MyData.file_name + \"_\" + \"DA_STB\" + str(n_iter)\n",
    "    A = Assignment(MyData, M_sum, label)\n",
    "\n",
    "    return A\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774362ba-1144-48c7-a256-1e069931ea82",
   "metadata": {},
   "source": [
    "## Initialize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54562267-7331-4872-b035-feb815c48d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preferences of the students\n",
    "# 'pref[i][k]' contains the position of the k-th ranked school in the preferences.\n",
    "# We assume the preferences to be strict\n",
    "# Note that preferences can be strict. We indicate this by a tuple () in the list.\n",
    "\n",
    "# Example paper\n",
    "n_stud = 4\n",
    "n_schools = 4\n",
    "\n",
    "file_name = \"Ex_paper\"\n",
    "\n",
    "# Preferences students\n",
    "pref = [['1', '3', '4', '2'],\n",
    "       ['1','4','3','2'],\n",
    "       # ['1', '4'],\n",
    "       ['2','3', '4', '1'],\n",
    "       #['2', '4', '3', '1']]\n",
    "        ['2', '4', '1', '3']]\n",
    "\n",
    "# Priorities schools\n",
    "prior = [[('A', 'B'), 'C', 'D'],\n",
    "        [('C', 'D'), 'A', 'B'],\n",
    "        ['B', 'D', ('A', 'C')],\n",
    "        ['A', 'C', ('B', 'D')]]\n",
    "#prior = [['D', 'A', 'B', 'C'],\n",
    "#        ['C', 'D', 'A', 'B'],\n",
    "#        ['B', 'D', 'A', 'C'],\n",
    "#        ['A', 'C', 'B', 'D']]\n",
    "\n",
    "\n",
    "# Capacities schools\n",
    "cap = [1,1,1,1]\n",
    "\n",
    "# Names of students and schools\n",
    "ID_stud = [\"A\", \"B\", \"C\", \"D\"]\n",
    "ID_school = [\"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "# Also create the random matching upon which we want to improve\n",
    "p = np.zeros(shape=(n_stud, n_schools))\n",
    "p[0][0] = 1/2\n",
    "p[1][0] = 1/2\n",
    "p[2][1] = 1/2\n",
    "p[3][1] = 1/2\n",
    "p[0][2] = 3/8\n",
    "p[2][2] = 3/8\n",
    "p[1][3] = 3/8\n",
    "p[3][3] = 3/8\n",
    "p[0][3] = 1/8\n",
    "p[2][3] = 1/8\n",
    "p[1][2] = 1/8\n",
    "p[3][2] = 1/8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2713baa0-f0ab-4efe-b12e-a56acbff26d4",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9c1abf4-9d79-462c-823f-55973799314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = DataGenParam(mean_pref = 8) # Default parameters\n",
    "MyData = generate_data(n_students=20, n_schools=5, parameters = parameters, name=\"Test_DataGen\", print_data=False, seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b33c068f-ccc4-40f1-af2a-e270e5902b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data instance has the following properties: \n",
      "\n",
      "\t20 students.\n",
      "\t5 schools. \n",
      "\n",
      " \tPREFERENCES:\n",
      "\t0\t2 1 0 3 4 \n",
      "\t1\t1 2 3 4 0 \n",
      "\t2\t2 0 1 3 4 \n",
      "\t3\t3 0 2 1 4 \n",
      "\t4\t2 0 3 1 4 \n",
      "\t5\t0 2 3 1 4 \n",
      "\t6\t1 0 2 3 4 \n",
      "\t7\t2 0 4 1 3 \n",
      "\t8\t2 3 1 4 0 \n",
      "\t9\t1 2 4 3 0 \n",
      "\t10\t2 1 0 4 3 \n",
      "\t11\t2 1 4 0 3 \n",
      "\t12\t3 4 0 2 1 \n",
      "\t13\t3 0 4 2 1 \n",
      "\t14\t1 0 3 4 2 \n",
      "\t15\t1 2 4 0 3 \n",
      "\t16\t2 0 3 1 4 \n",
      "\t17\t1 3 0 2 4 \n",
      "\t18\t1 2 4 0 3 \n",
      "\t19\t1 3 0 2 4 \n",
      "\n",
      "\n",
      " \tCAPACITIES & PRIORITIES:\n",
      "\t0\t5\t{0 12 17 10 16 5} {3 2 8 4 11 7} {19 15 14 6 13 9 18 1} \n",
      "\t1\t5\t{12 0 14 11 8 6} {9 4 10 5 18 17} {13 2 1 19 7 3 16 15} \n",
      "\t2\t8\t{11 14 9 19 7 15} {13 0 10 2 1 4} {17 12 16 6 3 18 5 8} \n",
      "\t3\t4\t{9 4 2 3 5 13} {10 0 12 18 11 15} {14 8 17 1 19 6 16 7} \n",
      "\t4\t1\t{3 12 8 10 5 18} {7 15 16 2 14 9} {4 11 0 1 19 17 6 13} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Uncomment next line for manually input data:\n",
    "#MyData = Data(n_stud, n_schools, pref, prior, cap, ID_stud, ID_school, file_name)\n",
    "print(MyData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e8e77cd-46ac-417a-8f2b-772c3f5dc315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students in ties: 20\n",
      "Tie-breaking rules needed: 2432902008176640000\n",
      "Tie-breaking rules sampled: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 844.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.025 0.975 0.    0.   ]\n",
      " [0.    0.    0.972 0.    0.028]\n",
      " [0.033 0.    0.967 0.    0.   ]\n",
      " [0.    0.    0.    1.    0.   ]\n",
      " [0.03  0.    0.97  0.    0.   ]\n",
      " [1.    0.    0.    0.    0.   ]\n",
      " [0.    1.    0.    0.    0.   ]\n",
      " [0.    0.    1.    0.    0.   ]\n",
      " [0.    0.508 0.    0.492 0.   ]\n",
      " [0.    0.851 0.149 0.    0.   ]\n",
      " [0.031 0.002 0.967 0.    0.   ]\n",
      " [0.    0.    1.    0.    0.   ]\n",
      " [0.    0.    0.    1.    0.   ]\n",
      " [0.    0.    0.    1.    0.   ]\n",
      " [0.    1.    0.    0.    0.   ]\n",
      " [0.    0.    1.    0.    0.   ]\n",
      " [1.    0.    0.    0.    0.   ]\n",
      " [0.17  0.809 0.    0.021 0.   ]\n",
      " [0.    0.805 0.    0.    0.195]\n",
      " [0.513 0.    0.    0.487 0.   ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "A = DA_STB(MyData, 1000, 0, True)\n",
    "print(A.assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "43896c1d-d24f-4bda-a240-a9859d3b66e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[683], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m A \u001b[38;5;241m=\u001b[39m Assignment(MyData, p, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEx_paper\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# To visualize assignment\u001b[39;00m\n\u001b[0;32m      4\u001b[0m A\u001b[38;5;241m.\u001b[39mvisualize()\n",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m, in \u001b[0;36mAssignment.__init__\u001b[1;34m(self, MyData, p, label)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(MyData\u001b[38;5;241m.\u001b[39mpref[i])):\n\u001b[0;32m     22\u001b[0m         \n\u001b[0;32m     23\u001b[0m         \u001b[38;5;66;03m# Convert pref[i][k] (school ID as string) to column index\u001b[39;00m\n\u001b[0;32m     24\u001b[0m         col_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(MyData\u001b[38;5;241m.\u001b[39mpref[i][j]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massignment_ranked[i][j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massignment[i][col_index]\n\u001b[0;32m     26\u001b[0m         counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#self.assignment_ranked = pd.DataFrame(ranked, columns = names)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Export assignment\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 7 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "A = Assignment(MyData, p, \"Ex_paper\")\n",
    "\n",
    "# To visualize assignment\n",
    "A.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fc5a49-fd8b-49e9-bcd6-5b95112b9a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stability constraints...\n",
      "Capacity constraints...\n",
      "\n",
      "Average rank before optimization: 1.3564500000000002.\n",
      "\n",
      "\n",
      "Constraints with auxiliary z...\n",
      "FOSD constraints...\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2595965\n",
      "Academic license - for non-commercial use only - expires 2025-12-05\n",
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: 11th Gen Intel(R) Core(TM) i7-1185G7 @ 3.00GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 43126 rows, 20401 columns and 257041 nonzeros\n",
      "Model fingerprint: 0x1fbfbc3f\n",
      "Variable types: 10301 continuous, 10100 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 8e+00]\n",
      "  Objective range  [5e-02, 3e-01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [5e-01, 8e+00]\n",
      "Presolve removed 29743 rows and 14207 columns\n",
      "Presolve time: 0.70s\n",
      "Presolved: 13383 rows, 6194 columns, 49766 nonzeros\n",
      "Variable types: 3467 continuous, 2727 integer (2727 binary)\n",
      "\n",
      "Root relaxation: objective 1.000000e+00, 3463 iterations, 0.16 seconds (0.12 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    1.00000    0   43          -    1.00000      -     -    1s\n",
      "     0     0    1.00000    0  108          -    1.00000      -     -    2s\n",
      "     0     0    1.00000    0   39          -    1.00000      -     -    3s\n",
      "     0     0    1.00000    0   43          -    1.00000      -     -    4s\n",
      "     0     0    1.00000    0   43          -    1.00000      -     -    4s\n",
      "H    0     0                       1.3516500    1.00000  26.0%     -    4s\n",
      "     0     0    1.00000    0   37    1.35165    1.00000  26.0%     -    5s\n",
      "     0     0    1.00000    0   37    1.35165    1.00000  26.0%     -    6s\n",
      "     0     0    1.00000    0   38    1.35165    1.00000  26.0%     -    6s\n",
      "     0     0    1.00000    0   40    1.35165    1.00000  26.0%     -    7s\n",
      "     0     0    1.00000    0   38    1.35165    1.00000  26.0%     -    7s\n",
      "     0     0    1.00000    0   47    1.35165    1.00000  26.0%     -    7s\n",
      "     0     0    1.00000    0   39    1.35165    1.00000  26.0%     -    9s\n",
      "     0     2    1.00000    0   39    1.35165    1.00000  26.0%     -   10s\n",
      "   193   265    1.00000   29  124    1.35165    1.00000  26.0%   339   15s\n",
      "   906   926    1.00000   55   48    1.35165    1.00000  26.0%   156   21s\n",
      "  1529  1190    1.00000   52   42    1.35165    1.00000  26.0%   141   25s\n",
      "  1532  1192    1.00000    3   37    1.35165    1.00000  26.0%   141   31s\n",
      "  1536  1195    1.05000  148   36    1.35165    1.00000  26.0%   141   35s\n",
      "  1542  1199    1.05000  150   45    1.35165    1.00000  26.0%   140   40s\n",
      "  1548  1203    1.00000   80   36    1.35165    1.00000  26.0%   140   45s\n",
      "  1623  1196    1.10000   25   35    1.35165    1.10000  18.6%   213   50s\n",
      "  1878  1356    1.15000   95   41    1.35165    1.10000  18.6%   196   55s\n",
      "  2162  1476    1.15000  153   49    1.35165    1.10000  18.6%   180   60s\n",
      "  2633  1715    1.30605  206   30    1.35165    1.10000  18.6%   159   65s\n",
      "  3132  1968    1.15000   94   25    1.35165    1.10000  18.6%   143   70s\n",
      "  3991  2363    1.32425  268   17    1.35165    1.10000  18.6%   125   75s\n",
      "  5001  2967    1.16258  153   58    1.35165    1.10000  18.6%   110   80s\n",
      "  6254  3916    1.15000  115   28    1.35165    1.10000  18.6%  96.7   85s\n",
      "  7931  5390 infeasible  227         1.35165    1.10000  18.6%  88.6   90s\n",
      "  9374  6798    1.17010  102   39    1.35165    1.10000  18.6%  84.3   95s\n",
      " 10594  7279    1.15000   67   39    1.35165    1.10000  18.6%  79.5  100s\n",
      " 10615  7293    1.30735  210   17    1.35165    1.15000  14.9%  79.3  105s\n",
      " 10890  7654    1.15000   34   23    1.35165    1.15000  14.9%  80.5  110s\n",
      " 11911  8286    1.25000  189   15    1.35165    1.15000  14.9%  76.0  115s\n",
      "H12408  8031                       1.3516499    1.15000  14.9%  73.5  117s\n",
      "H12683  8023                       1.3516498    1.15000  14.9%  72.2  118s\n",
      " 13359  8562    1.33170  379    5    1.35165    1.15000  14.9%  69.1  120s\n",
      "H14765  8688                       1.3516498    1.15000  14.9%  64.3  124s\n",
      "H14768  8374                       1.3516497    1.15000  14.9%  64.3  124s\n",
      " 14769  8536    1.25000  170   12    1.35165    1.15000  14.9%  64.3  125s\n",
      "H16371  9250                       1.3516497    1.15000  14.9%  59.4  128s\n",
      " 17380 10021    1.33170  458   13    1.35165    1.15000  14.9%  56.5  130s\n",
      "H17599  9666                       1.3516489    1.15000  14.9%  56.0  130s\n",
      " 20628 11464    1.31690  270   16    1.35165    1.15000  14.9%  50.7  135s\n",
      " 20933 11385    1.34125  414   28    1.35165    1.16689  13.7%  50.5  140s\n",
      " 21183 11615    1.25000   56   24    1.35165    1.20000  11.2%  51.4  145s\n",
      " 22327 12369    1.30000  190    3    1.35165    1.20000  11.2%  49.6  150s\n",
      " 24653 13789 infeasible   54         1.35165    1.20000  11.2%  45.9  155s\n",
      " 28155 16092    1.30000  274    4    1.35165    1.20000  11.2%  41.7  160s\n",
      "H30416 16440                       1.3516485    1.20000  11.2%  39.9  163s\n",
      "H30417 15898                       1.3516481    1.20000  11.2%  39.9  163s\n",
      "H30422 15381                       1.3516481    1.20000  11.2%  39.9  163s\n",
      " 31184 18703    1.30000  192    9    1.35165    1.20000  11.2%  39.3  169s\n",
      " 34648 17651     cutoff  432         1.35165    1.20000  11.2%  36.6  170s\n",
      " 38478 20175    1.25000  143   12    1.35165    1.20000  11.2%  34.2  175s\n",
      " 41371 21153    1.25000  123   21    1.35165    1.20015  11.2%  32.7  180s\n",
      " 41712 21384    1.25000   84   11    1.35165    1.25000  7.52%  32.8  185s\n",
      " 43374 22782    1.30000  291    6    1.35165    1.25000  7.52%  31.9  190s\n",
      " 46030 24072    1.30000  156    7    1.35165    1.25000  7.52%  30.7  195s\n",
      " 48857 26264    1.30000  135    3    1.35165    1.25000  7.52%  29.7  200s\n",
      " 51887 27721    1.25000   67   39    1.35165    1.25000  7.52%  28.9  210s\n",
      " 51900 27730    1.30000  260   10    1.35165    1.25000  7.52%  28.9  215s\n",
      " 52303 28343    1.25000  118   12    1.35165    1.25000  7.52%  29.0  220s\n",
      " 53552 29080    1.33170  269   10    1.35165    1.25000  7.52%  28.8  225s\n",
      " 55770 30459    1.30000  284    3    1.35165    1.25000  7.52%  28.4  230s\n",
      " 57996 31778    1.30000  205    8    1.35165    1.25000  7.52%  28.0  235s\n",
      " 62601 34311    1.33170  274    9    1.35165    1.25000  7.52%  27.2  240s\n",
      " 66918 36754    1.30000  227    8    1.35165    1.25000  7.52%  26.4  245s\n",
      " 71319 38625    1.33170  288    6    1.35165    1.25000  7.52%  25.6  250s\n",
      " 74487 40158    1.27507  146    6    1.35165    1.25000  7.52%  25.1  255s\n",
      " 78768 42314    1.33170  267    6    1.35165    1.25000  7.52%  24.6  260s\n",
      " 82276 44096    1.34870  367    5    1.35165    1.25000  7.52%  24.2  265s\n",
      " 86276 46042    1.34895  292   10    1.35165    1.25000  7.52%  23.8  270s\n",
      " 90010 47877    1.33170  292    8    1.35165    1.25000  7.52%  23.5  275s\n",
      " 93806 50205    1.34125  252    4    1.35165    1.25000  7.52%  23.2  280s\n",
      " 97551 51965    1.33405  255   12    1.35165    1.25000  7.52%  23.0  285s\n",
      " 102158 53790    1.30000  186    5    1.35165    1.25000  7.52%  22.6  290s\n",
      " 106408 55800    1.34870  280    7    1.35165    1.25000  7.52%  22.3  295s\n",
      " 110095 57717    1.34125  279    3    1.35165    1.25000  7.52%  22.1  300s\n",
      " 114307 60223    1.30730  256    8    1.35165    1.25000  7.52%  21.9  305s\n",
      " 116591 61568    1.33170  272    7    1.35165    1.25000  7.52%  21.9  310s\n",
      " 120761 63445    1.25000  123   15    1.35165    1.25000  7.52%  21.6  315s\n",
      " 124816 65445    1.30000  161    4    1.35165    1.25000  7.52%  21.4  320s\n",
      " 129130 67489    1.34105  260    6    1.35165    1.25000  7.52%  21.1  325s\n",
      " 132355 69292    1.30000  257    5    1.35165    1.25000  7.52%  21.1  330s\n",
      " 134753 70324    1.26256  135   10    1.35165    1.25000  7.52%  21.0  335s\n",
      " 137520 72925    1.30000  139    7    1.35165    1.25000  7.52%  21.0  340s\n",
      " 141217 75228    1.35025  275    7    1.35165    1.25000  7.52%  20.8  345s\n",
      " 145520 78800    1.30000  164    3    1.35165    1.25000  7.52%  20.6  350s\n",
      " 148810 81859    1.25000  123   12    1.35165    1.25000  7.52%  20.5  355s\n",
      " 153287 85095    1.30000  157    3    1.35165    1.25000  7.52%  20.4  360s\n",
      " 155370 87417    1.30000  178    5    1.35165    1.25000  7.52%  20.3  365s\n",
      " 158836 90105    1.30000  169    3    1.35165    1.25000  7.52%  20.1  370s\n",
      " 163575 94088    1.25405  125   15    1.35165    1.25000  7.52%  20.0  375s\n",
      " 165255 95626    1.33170  257    9    1.35165    1.25000  7.52%  19.9  380s\n",
      " 168938 98855    1.30000  224    3    1.35165    1.25000  7.52%  19.9  385s\n",
      " 172296 101890    1.30000  210    6    1.35165    1.25000  7.52%  19.8  390s\n",
      " 175577 104393    1.30000  256    3    1.35165    1.25000  7.52%  19.7  395s\n",
      " 179800 107562    1.30000  180    6    1.35165    1.25000  7.52%  19.5  400s\n",
      " 183360 110465    1.34125  267    3    1.35165    1.25000  7.52%  19.4  405s\n",
      " 187822 113895    1.27512  132   11    1.35165    1.25000  7.52%  19.2  410s\n",
      " 188947 114991    1.30000  211    8    1.35165    1.25000  7.52%  19.2  415s\n",
      " 193118 118013    1.35025  290    3    1.35165    1.25000  7.52%  19.2  420s\n",
      " 196211 120611    1.30000  176    7    1.35165    1.25000  7.52%  19.1  425s\n",
      " 199152 122780    1.30000  228    4    1.35165    1.25000  7.52%  19.0  430s\n",
      " 203444 126388     cutoff  268         1.35165    1.25000  7.52%  18.9  435s\n",
      " 205955 128496    1.25000  120    9    1.35165    1.25000  7.52%  18.9  440s\n",
      " 209657 131354    1.30000  219    6    1.35165    1.25000  7.52%  18.8  445s\n",
      " 211521 132977    1.30000  168    3    1.35165    1.25000  7.52%  18.7  450s\n",
      " 214768 135533    1.30000  188    3    1.35165    1.25000  7.52%  18.7  455s\n",
      " 218163 138473    1.26256  128   12    1.35165    1.25000  7.52%  18.6  460s\n",
      " 220882 140606    1.30000  213    6    1.35165    1.25000  7.52%  18.5  465s\n",
      " 224528 143794    1.35000  320    2    1.35165    1.25000  7.52%  18.5  470s\n",
      " 227787 146469    1.30000  211    4    1.35165    1.25000  7.52%  18.4  475s\n",
      " 231521 149441    1.30000  235    3    1.35165    1.25000  7.52%  18.4  480s\n",
      " 236609 153592    1.30000  259    6    1.35165    1.25000  7.52%  18.3  485s\n",
      " 238586 154880    1.35025  293    7    1.35165    1.25000  7.52%  18.2  490s\n",
      " 242056 158196    1.30000  189    3    1.35165    1.25000  7.52%  18.2  495s\n",
      " 245121 160786     cutoff  280         1.35165    1.25000  7.52%  18.1  500s\n",
      " 248210 163555    1.26256  125    9    1.35165    1.25000  7.52%  18.2  505s\n",
      " 251414 166528    1.33170  238   10    1.35165    1.25000  7.52%  18.2  510s\n",
      " 254951 169457     cutoff  277         1.35165    1.25000  7.52%  18.2  515s\n",
      " 259074 172678    1.30000  183    4    1.35165    1.25000  7.52%  18.1  520s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\iostream.py:624\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    616\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    618\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    619\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread,\n\u001b[0;32m    620\u001b[0m             msg,\n\u001b[0;32m    621\u001b[0m             ident\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic,\n\u001b[0;32m    622\u001b[0m         )\n\u001b[1;32m--> 624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, string: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mint\u001b[39m]:  \u001b[38;5;66;03m# type:ignore[override]\u001b[39;00m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Write to current stream after encoding if necessary\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    631\u001b[0m \n\u001b[0;32m    632\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    634\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(string, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gurobipy._core.logcallbackstub'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tdemeule\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\iostream.py\", line 624, in write\n",
      "    def write(self, string: str) -> Optional[int]:  # type:ignore[override]\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 265425 178097    1.34125  268    2    1.35165    1.25000  7.52%  18.0  535s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\iostream.py:624\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    616\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    618\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    619\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread,\n\u001b[0;32m    620\u001b[0m             msg,\n\u001b[0;32m    621\u001b[0m             ident\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic,\n\u001b[0;32m    622\u001b[0m         )\n\u001b[1;32m--> 624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, string: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mint\u001b[39m]:  \u001b[38;5;66;03m# type:ignore[override]\u001b[39;00m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Write to current stream after encoding if necessary\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    631\u001b[0m \n\u001b[0;32m    632\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    634\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(string, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gurobipy._core.logcallbackstub'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tdemeule\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\iostream.py\", line 624, in write\n",
      "    def write(self, string: str) -> Optional[int]:  # type:ignore[override]\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 271227 182979    1.27500  122   15    1.35165    1.25000  7.52%  18.0  545s\n",
      " 274408 185518    1.30000  196    5    1.35165    1.25000  7.52%  17.9  550s\n",
      " 276778 187501    1.30000  158    3    1.35165    1.25000  7.52%  17.9  555s\n",
      " 280843 190793    1.30000  167    5    1.35165    1.25000  7.52%  17.8  560s\n"
     ]
    }
   ],
   "source": [
    "MyModel = Model(MyData, A, True)\n",
    "q = MyModel.Solve(\"IMPR_RANK\", \"GUROBI\", True)\n",
    "#q = MyModel.Solve(\"STABLE\", \"GUROBI\", True)\n",
    "\n",
    "# The problem is solved using PuLP's choice of Solver\n",
    "# MyModel.model.solve(GUROBI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3baa5c-1f4f-4aaf-9124-b7a0e830cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModel.print_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5fd6dc-54ee-4926-ae1d-57b0e7982182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the solution\n",
    "q.visualize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a5f22f-3855-4346-bd03-4ee5ce105d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asses the difference\n",
    "diff = Assignment(MyData, q.assignment - p, \"Ex_paper_Diff\")\n",
    "diff.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "41f8f9e4-b294-492a-bce2-b6a409b04c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(gale_shapley(MyData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "80b5bddf-b8cb-4a2e-8a6b-754e32cb3462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(MyData.pref[6][0]) -1\n",
    "MyData.ID_school.index(MyData.pref[0][0])\n",
    "MyData.ID_school\n",
    "MyData.ID_school.index(MyData.pref[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e681d59-b360-4ab3-b3a0-580dd706ad5e",
   "metadata": {},
   "source": [
    "## Appendix: minimal working code pulp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c0b2b5-5798-479e-93df-a8f0f047d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a simple MILP formulation in Gurobi \n",
    "\n",
    "from pulp import LpProblem, LpVariable, LpMaximize, GUROBI\n",
    "\n",
    "# Define a simple problem\n",
    "prob = LpProblem(\"SimpleProblem\", LpMaximize)\n",
    "\n",
    "# Define variables\n",
    "x = LpVariable(\"x\", lowBound=0)  # x >= 0\n",
    "y = LpVariable(\"y\", lowBound=0)  # y >= 0\n",
    "\n",
    "# Objective Function\n",
    "prob += 3 * x + 2 * y, \"Objective\"\n",
    "\n",
    "# Constraints\n",
    "prob += 2 * x + y <= 20, \"Constraint 1\"\n",
    "prob += 4 * x + 3 * y <= 50, \"Constraint 2\"\n",
    "\n",
    "# Solve using Gurobi API\n",
    "prob.solve(GUROBI())\n",
    "\n",
    "# Print the results\n",
    "print(f\"Status: {prob.status}\")\n",
    "print(f\"x = {x.varValue}\")\n",
    "print(f\"y = {y.varValue}\")\n",
    "prob.writeLP(\"Test.lp\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
